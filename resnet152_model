digraph {
	graph [size="442.65,442.65"]
	node [align=left fontname=monospace fontsize=10 height=0.2 ranksep=0.1 shape=box style=filled]
	1607400565056 [label="
 (1, 1000)" fillcolor=darkolivegreen1]
	1607275723360 [label=AddmmBackward0]
	1607288176112 -> 1607275723360
	1607400038288 [label="fc.bias
 (1000)" fillcolor=lightblue]
	1607400038288 -> 1607288176112
	1607288176112 [label=AccumulateGrad]
	1607275718752 -> 1607275723360
	1607275718752 [label=ViewBackward0]
	1607281192160 -> 1607275718752
	1607281192160 [label=MeanBackward1]
	1607285451472 -> 1607281192160
	1607285451472 [label=ReluBackward0]
	1607289354512 -> 1607285451472
	1607289354512 [label=AddBackward0]
	1607286568992 -> 1607289354512
	1607286568992 [label=CudnnBatchNormBackward0]
	1607284119520 -> 1607286568992
	1607284119520 [label=ConvolutionBackward0]
	1607289727984 -> 1607284119520
	1607289727984 [label=ReluBackward0]
	1607289721888 -> 1607289727984
	1607289721888 [label=CudnnBatchNormBackward0]
	1607290759024 -> 1607289721888
	1607290759024 [label=ConvolutionBackward0]
	1607290760176 -> 1607290759024
	1607290760176 [label=ReluBackward0]
	1607290760224 -> 1607290760176
	1607290760224 [label=CudnnBatchNormBackward0]
	1607290763440 -> 1607290760224
	1607290763440 [label=ConvolutionBackward0]
	1607287480352 -> 1607290763440
	1607287480352 [label=ReluBackward0]
	1607290760656 -> 1607287480352
	1607290760656 [label=AddBackward0]
	1607290760416 -> 1607290760656
	1607290760416 [label=CudnnBatchNormBackward0]
	1607290764880 -> 1607290760416
	1607290764880 [label=ConvolutionBackward0]
	1607290758688 -> 1607290764880
	1607290758688 [label=ReluBackward0]
	1607290765216 -> 1607290758688
	1607290765216 [label=CudnnBatchNormBackward0]
	1607290764784 -> 1607290765216
	1607290764784 [label=ConvolutionBackward0]
	1607290764208 -> 1607290764784
	1607290764208 [label=ReluBackward0]
	1607290763776 -> 1607290764208
	1607290763776 [label=CudnnBatchNormBackward0]
	1607290763296 -> 1607290763776
	1607290763296 [label=ConvolutionBackward0]
	1607290760704 -> 1607290763296
	1607290760704 [label=ReluBackward0]
	1607290762144 -> 1607290760704
	1607290762144 [label=AddBackward0]
	1607290761808 -> 1607290762144
	1607290761808 [label=CudnnBatchNormBackward0]
	1607290761232 -> 1607290761808
	1607290761232 [label=ConvolutionBackward0]
	1607290760512 -> 1607290761232
	1607290760512 [label=ReluBackward0]
	1607290759984 -> 1607290760512
	1607290759984 [label=CudnnBatchNormBackward0]
	1607290759360 -> 1607290759984
	1607290759360 [label=ConvolutionBackward0]
	1607290759792 -> 1607290759360
	1607290759792 [label=ReluBackward0]
	1607285390496 -> 1607290759792
	1607285390496 [label=CudnnBatchNormBackward0]
	1607249824640 -> 1607285390496
	1607249824640 [label=ConvolutionBackward0]
	1607400553968 -> 1607249824640
	1607400553968 [label=ReluBackward0]
	1607400553440 -> 1607400553968
	1607400553440 [label=AddBackward0]
	1607400554304 -> 1607400553440
	1607400554304 [label=CudnnBatchNormBackward0]
	1607400552960 -> 1607400554304
	1607400552960 [label=ConvolutionBackward0]
	1607400552432 -> 1607400552960
	1607400552432 [label=ReluBackward0]
	1607400551904 -> 1607400552432
	1607400551904 [label=CudnnBatchNormBackward0]
	1607400551712 -> 1607400551904
	1607400551712 [label=ConvolutionBackward0]
	1607400551136 -> 1607400551712
	1607400551136 [label=ReluBackward0]
	1607400550560 -> 1607400551136
	1607400550560 [label=CudnnBatchNormBackward0]
	1607400550320 -> 1607400550560
	1607400550320 [label=ConvolutionBackward0]
	1607400553296 -> 1607400550320
	1607400553296 [label=ReluBackward0]
	1607400549504 -> 1607400553296
	1607400549504 [label=AddBackward0]
	1607400549168 -> 1607400549504
	1607400549168 [label=CudnnBatchNormBackward0]
	1607400548736 -> 1607400549168
	1607400548736 [label=ConvolutionBackward0]
	1607400548208 -> 1607400548736
	1607400548208 [label=ReluBackward0]
	1607400547824 -> 1607400548208
	1607400547824 [label=CudnnBatchNormBackward0]
	1607400547584 -> 1607400547824
	1607400547584 [label=ConvolutionBackward0]
	1607400547008 -> 1607400547584
	1607400547008 [label=ReluBackward0]
	1607400546624 -> 1607400547008
	1607400546624 [label=CudnnBatchNormBackward0]
	1607400546288 -> 1607400546624
	1607400546288 [label=ConvolutionBackward0]
	1607400549360 -> 1607400546288
	1607400549360 [label=ReluBackward0]
	1607400545664 -> 1607400549360
	1607400545664 [label=AddBackward0]
	1607400545328 -> 1607400545664
	1607400545328 [label=CudnnBatchNormBackward0]
	1607400544944 -> 1607400545328
	1607400544944 [label=ConvolutionBackward0]
	1607400544320 -> 1607400544944
	1607400544320 [label=ReluBackward0]
	1607400543840 -> 1607400544320
	1607400543840 [label=CudnnBatchNormBackward0]
	1607400543552 -> 1607400543840
	1607400543552 [label=ConvolutionBackward0]
	1607400542976 -> 1607400543552
	1607400542976 [label=ReluBackward0]
	1607400542640 -> 1607400542976
	1607400542640 [label=CudnnBatchNormBackward0]
	1607400542400 -> 1607400542640
	1607400542400 [label=ConvolutionBackward0]
	1607400545472 -> 1607400542400
	1607400545472 [label=ReluBackward0]
	1607400541584 -> 1607400545472
	1607400541584 [label=AddBackward0]
	1607400541440 -> 1607400541584
	1607400541440 [label=CudnnBatchNormBackward0]
	1607400540960 -> 1607400541440
	1607400540960 [label=ConvolutionBackward0]
	1607400540480 -> 1607400540960
	1607400540480 [label=ReluBackward0]
	1607400540096 -> 1607400540480
	1607400540096 [label=CudnnBatchNormBackward0]
	1607400539808 -> 1607400540096
	1607400539808 [label=ConvolutionBackward0]
	1607400539280 -> 1607400539808
	1607400539280 [label=ReluBackward0]
	1607400538944 -> 1607400539280
	1607400538944 [label=CudnnBatchNormBackward0]
	1607400538608 -> 1607400538944
	1607400538608 [label=ConvolutionBackward0]
	1607400541536 -> 1607400538608
	1607400541536 [label=ReluBackward0]
	1607400548640 -> 1607400541536
	1607400548640 [label=AddBackward0]
	1607400549936 -> 1607400548640
	1607400549936 [label=CudnnBatchNormBackward0]
	1607400549408 -> 1607400549936
	1607400549408 [label=ConvolutionBackward0]
	1607400553776 -> 1607400549408
	1607400553776 [label=ReluBackward0]
	1607400254448 -> 1607400553776
	1607400254448 [label=CudnnBatchNormBackward0]
	1607400252432 -> 1607400254448
	1607400252432 [label=ConvolutionBackward0]
	1607400255552 -> 1607400252432
	1607400255552 [label=ReluBackward0]
	1607400259536 -> 1607400255552
	1607400259536 [label=CudnnBatchNormBackward0]
	1607400259344 -> 1607400259536
	1607400259344 [label=ConvolutionBackward0]
	1607400548784 -> 1607400259344
	1607400548784 [label=ReluBackward0]
	1607400258432 -> 1607400548784
	1607400258432 [label=AddBackward0]
	1607400258000 -> 1607400258432
	1607400258000 [label=CudnnBatchNormBackward0]
	1607400257568 -> 1607400258000
	1607400257568 [label=ConvolutionBackward0]
	1607400256944 -> 1607400257568
	1607400256944 [label=ReluBackward0]
	1607400256368 -> 1607400256944
	1607400256368 [label=CudnnBatchNormBackward0]
	1607400256080 -> 1607400256368
	1607400256080 [label=ConvolutionBackward0]
	1607400255408 -> 1607400256080
	1607400255408 [label=ReluBackward0]
	1607400254928 -> 1607400255408
	1607400254928 [label=CudnnBatchNormBackward0]
	1607400254640 -> 1607400254928
	1607400254640 [label=ConvolutionBackward0]
	1607400258240 -> 1607400254640
	1607400258240 [label=ReluBackward0]
	1607400253776 -> 1607400258240
	1607400253776 [label=AddBackward0]
	1607400253488 -> 1607400253776
	1607400253488 [label=CudnnBatchNormBackward0]
	1607400253056 -> 1607400253488
	1607400253056 [label=ConvolutionBackward0]
	1607400252480 -> 1607400253056
	1607400252480 [label=ReluBackward0]
	1607400252000 -> 1607400252480
	1607400252000 [label=CudnnBatchNormBackward0]
	1607400251616 -> 1607400252000
	1607400251616 [label=ConvolutionBackward0]
	1607400250848 -> 1607400251616
	1607400250848 [label=ReluBackward0]
	1607400250464 -> 1607400250848
	1607400250464 [label=CudnnBatchNormBackward0]
	1607400250080 -> 1607400250464
	1607400250080 [label=ConvolutionBackward0]
	1607400253632 -> 1607400250080
	1607400253632 [label=ReluBackward0]
	1607400249312 -> 1607400253632
	1607400249312 [label=AddBackward0]
	1607400249072 -> 1607400249312
	1607400249072 [label=CudnnBatchNormBackward0]
	1607400248400 -> 1607400249072
	1607400248400 [label=ConvolutionBackward0]
	1607400247632 -> 1607400248400
	1607400247632 [label=ReluBackward0]
	1607400247104 -> 1607400247632
	1607400247104 [label=CudnnBatchNormBackward0]
	1607400246672 -> 1607400247104
	1607400246672 [label=ConvolutionBackward0]
	1607400246096 -> 1607400246672
	1607400246096 [label=ReluBackward0]
	1607400245712 -> 1607400246096
	1607400245712 [label=CudnnBatchNormBackward0]
	1607400245376 -> 1607400245712
	1607400245376 [label=ConvolutionBackward0]
	1607400249216 -> 1607400245376
	1607400249216 [label=ReluBackward0]
	1607400244320 -> 1607400249216
	1607400244320 [label=AddBackward0]
	1607400244080 -> 1607400244320
	1607400244080 [label=CudnnBatchNormBackward0]
	1607400243504 -> 1607400244080
	1607400243504 [label=ConvolutionBackward0]
	1607400249456 -> 1607400243504
	1607400249456 [label=ReluBackward0]
	1607400155280 -> 1607400249456
	1607400155280 [label=CudnnBatchNormBackward0]
	1607400155808 -> 1607400155280
	1607400155808 [label=ConvolutionBackward0]
	1607400149904 -> 1607400155808
	1607400149904 [label=ReluBackward0]
	1607400157104 -> 1607400149904
	1607400157104 [label=CudnnBatchNormBackward0]
	1607400145824 -> 1607400157104
	1607400145824 [label=ConvolutionBackward0]
	1607400244128 -> 1607400145824
	1607400244128 [label=ReluBackward0]
	1607400160512 -> 1607400244128
	1607400160512 [label=AddBackward0]
	1607400160176 -> 1607400160512
	1607400160176 [label=CudnnBatchNormBackward0]
	1607400159744 -> 1607400160176
	1607400159744 [label=ConvolutionBackward0]
	1607400159216 -> 1607400159744
	1607400159216 [label=ReluBackward0]
	1607400158976 -> 1607400159216
	1607400158976 [label=CudnnBatchNormBackward0]
	1607400158688 -> 1607400158976
	1607400158688 [label=ConvolutionBackward0]
	1607400158112 -> 1607400158688
	1607400158112 [label=ReluBackward0]
	1607400157632 -> 1607400158112
	1607400157632 [label=CudnnBatchNormBackward0]
	1607400157344 -> 1607400157632
	1607400157344 [label=ConvolutionBackward0]
	1607400160416 -> 1607400157344
	1607400160416 [label=ReluBackward0]
	1607400156288 -> 1607400160416
	1607400156288 [label=AddBackward0]
	1607400155904 -> 1607400156288
	1607400155904 [label=CudnnBatchNormBackward0]
	1607400155520 -> 1607400155904
	1607400155520 [label=ConvolutionBackward0]
	1607400154752 -> 1607400155520
	1607400154752 [label=ReluBackward0]
	1607400154128 -> 1607400154752
	1607400154128 [label=CudnnBatchNormBackward0]
	1607400153648 -> 1607400154128
	1607400153648 [label=ConvolutionBackward0]
	1607400152832 -> 1607400153648
	1607400152832 [label=ReluBackward0]
	1607400152208 -> 1607400152832
	1607400152208 [label=CudnnBatchNormBackward0]
	1607400151872 -> 1607400152208
	1607400151872 [label=ConvolutionBackward0]
	1607400156144 -> 1607400151872
	1607400156144 [label=ReluBackward0]
	1607400150720 -> 1607400156144
	1607400150720 [label=AddBackward0]
	1607400150432 -> 1607400150720
	1607400150432 [label=CudnnBatchNormBackward0]
	1607400149712 -> 1607400150432
	1607400149712 [label=ConvolutionBackward0]
	1607400148896 -> 1607400149712
	1607400148896 [label=ReluBackward0]
	1607400148416 -> 1607400148896
	1607400148416 [label=CudnnBatchNormBackward0]
	1607400147936 -> 1607400148416
	1607400147936 [label=ConvolutionBackward0]
	1607400147168 -> 1607400147936
	1607400147168 [label=ReluBackward0]
	1607400146400 -> 1607400147168
	1607400146400 [label=CudnnBatchNormBackward0]
	1607400146352 -> 1607400146400
	1607400146352 [label=ConvolutionBackward0]
	1607400150528 -> 1607400146352
	1607400150528 [label=ReluBackward0]
	1607400145104 -> 1607400150528
	1607400145104 [label=AddBackward0]
	1607400149088 -> 1607400145104
	1607400149088 [label=CudnnBatchNormBackward0]
	1607286903648 -> 1607400149088
	1607286903648 [label=ConvolutionBackward0]
	1607400333680 -> 1607286903648
	1607400333680 [label=ReluBackward0]
	1607400339248 -> 1607400333680
	1607400339248 [label=CudnnBatchNormBackward0]
	1607400339104 -> 1607400339248
	1607400339104 [label=ConvolutionBackward0]
	1607400330896 -> 1607400339104
	1607400330896 [label=ReluBackward0]
	1607400339056 -> 1607400330896
	1607400339056 [label=CudnnBatchNormBackward0]
	1607400334112 -> 1607400339056
	1607400334112 [label=ConvolutionBackward0]
	1607400149856 -> 1607400334112
	1607400149856 [label=ReluBackward0]
	1607400328112 -> 1607400149856
	1607400328112 [label=AddBackward0]
	1607400337712 -> 1607400328112
	1607400337712 [label=CudnnBatchNormBackward0]
	1607400341456 -> 1607400337712
	1607400341456 [label=ConvolutionBackward0]
	1607400340928 -> 1607400341456
	1607400340928 [label=ReluBackward0]
	1607400340352 -> 1607400340928
	1607400340352 [label=CudnnBatchNormBackward0]
	1607400339968 -> 1607400340352
	1607400339968 [label=ConvolutionBackward0]
	1607400339344 -> 1607400339968
	1607400339344 [label=ReluBackward0]
	1607400338960 -> 1607400339344
	1607400338960 [label=CudnnBatchNormBackward0]
	1607400338624 -> 1607400338960
	1607400338624 [label=ConvolutionBackward0]
	1607400340208 -> 1607400338624
	1607400340208 [label=ReluBackward0]
	1607400337856 -> 1607400340208
	1607400337856 [label=AddBackward0]
	1607400337664 -> 1607400337856
	1607400337664 [label=CudnnBatchNormBackward0]
	1607400337280 -> 1607400337664
	1607400337280 [label=ConvolutionBackward0]
	1607400336608 -> 1607400337280
	1607400336608 [label=ReluBackward0]
	1607400336128 -> 1607400336608
	1607400336128 [label=CudnnBatchNormBackward0]
	1607400335936 -> 1607400336128
	1607400335936 [label=ConvolutionBackward0]
	1607400335408 -> 1607400335936
	1607400335408 [label=ReluBackward0]
	1607400335168 -> 1607400335408
	1607400335168 [label=CudnnBatchNormBackward0]
	1607400334736 -> 1607400335168
	1607400334736 [label=ConvolutionBackward0]
	1607400336512 -> 1607400334736
	1607400336512 [label=ReluBackward0]
	1607400333632 -> 1607400336512
	1607400333632 [label=AddBackward0]
	1607400333248 -> 1607400333632
	1607400333248 [label=CudnnBatchNormBackward0]
	1607400332672 -> 1607400333248
	1607400332672 [label=ConvolutionBackward0]
	1607400332000 -> 1607400332672
	1607400332000 [label=ReluBackward0]
	1607400331760 -> 1607400332000
	1607400331760 [label=CudnnBatchNormBackward0]
	1607400331520 -> 1607400331760
	1607400331520 [label=ConvolutionBackward0]
	1607400330752 -> 1607400331520
	1607400330752 [label=ReluBackward0]
	1607400330368 -> 1607400330752
	1607400330368 [label=CudnnBatchNormBackward0]
	1607400329936 -> 1607400330368
	1607400329936 [label=ConvolutionBackward0]
	1607400333440 -> 1607400329936
	1607400333440 [label=ReluBackward0]
	1607400329552 -> 1607400333440
	1607400329552 [label=AddBackward0]
	1607400329168 -> 1607400329552
	1607400329168 [label=CudnnBatchNormBackward0]
	1607400328832 -> 1607400329168
	1607400328832 [label=ConvolutionBackward0]
	1607400328160 -> 1607400328832
	1607400328160 [label=ReluBackward0]
	1607400327920 -> 1607400328160
	1607400327920 [label=CudnnBatchNormBackward0]
	1607400327680 -> 1607400327920
	1607400327680 [label=ConvolutionBackward0]
	1607400326960 -> 1607400327680
	1607400326960 [label=ReluBackward0]
	1607400340496 -> 1607400326960
	1607400340496 [label=CudnnBatchNormBackward0]
	1607400326336 -> 1607400340496
	1607400326336 [label=ConvolutionBackward0]
	1607400329408 -> 1607400326336
	1607400329408 [label=ReluBackward0]
	1607400325328 -> 1607400329408
	1607400325328 [label=AddBackward0]
	1607400332336 -> 1607400325328
	1607400332336 [label=CudnnBatchNormBackward0]
	1607400332768 -> 1607400332336
	1607400332768 [label=ConvolutionBackward0]
	1607400335600 -> 1607400332768
	1607400335600 [label=ReluBackward0]
	1607400333200 -> 1607400335600
	1607400333200 [label=CudnnBatchNormBackward0]
	1607400325232 -> 1607400333200
	1607400325232 [label=ConvolutionBackward0]
	1607400330416 -> 1607400325232
	1607400330416 [label=ReluBackward0]
	1607400329072 -> 1607400330416
	1607400329072 [label=CudnnBatchNormBackward0]
	1607400429536 -> 1607400329072
	1607400429536 [label=ConvolutionBackward0]
	1607400334496 -> 1607400429536
	1607400334496 [label=ReluBackward0]
	1607400435104 -> 1607400334496
	1607400435104 [label=AddBackward0]
	1607400429344 -> 1607400435104
	1607400429344 [label=CudnnBatchNormBackward0]
	1607400424208 -> 1607400429344
	1607400424208 [label=ConvolutionBackward0]
	1607400439280 -> 1607400424208
	1607400439280 [label=ReluBackward0]
	1607400438944 -> 1607400439280
	1607400438944 [label=CudnnBatchNormBackward0]
	1607400438656 -> 1607400438944
	1607400438656 [label=ConvolutionBackward0]
	1607400438080 -> 1607400438656
	1607400438080 [label=ReluBackward0]
	1607400437744 -> 1607400438080
	1607400437744 [label=CudnnBatchNormBackward0]
	1607400437552 -> 1607400437744
	1607400437552 [label=ConvolutionBackward0]
	1607400437216 -> 1607400437552
	1607400437216 [label=ReluBackward0]
	1607400437792 -> 1607400437216
	1607400437792 [label=AddBackward0]
	1607400436592 -> 1607400437792
	1607400436592 [label=CudnnBatchNormBackward0]
	1607400436112 -> 1607400436592
	1607400436112 [label=ConvolutionBackward0]
	1607400435584 -> 1607400436112
	1607400435584 [label=ReluBackward0]
	1607400435248 -> 1607400435584
	1607400435248 [label=CudnnBatchNormBackward0]
	1607400434912 -> 1607400435248
	1607400434912 [label=ConvolutionBackward0]
	1607400434432 -> 1607400434912
	1607400434432 [label=ReluBackward0]
	1607400434144 -> 1607400434432
	1607400434144 [label=CudnnBatchNormBackward0]
	1607400433856 -> 1607400434144
	1607400433856 [label=ConvolutionBackward0]
	1607400436736 -> 1607400433856
	1607400436736 [label=ReluBackward0]
	1607400433088 -> 1607400436736
	1607400433088 [label=AddBackward0]
	1607400432896 -> 1607400433088
	1607400432896 [label=CudnnBatchNormBackward0]
	1607400438128 -> 1607400432896
	1607400438128 [label=ConvolutionBackward0]
	1607400432176 -> 1607400438128
	1607400432176 [label=ReluBackward0]
	1607400431648 -> 1607400432176
	1607400431648 [label=CudnnBatchNormBackward0]
	1607400431360 -> 1607400431648
	1607400431360 [label=ConvolutionBackward0]
	1607400430832 -> 1607400431360
	1607400430832 [label=ReluBackward0]
	1607400430400 -> 1607400430832
	1607400430400 [label=CudnnBatchNormBackward0]
	1607400430208 -> 1607400430400
	1607400430208 [label=ConvolutionBackward0]
	1607400432848 -> 1607400430208
	1607400432848 [label=ReluBackward0]
	1607400429680 -> 1607400432848
	1607400429680 [label=AddBackward0]
	1607400429296 -> 1607400429680
	1607400429296 [label=CudnnBatchNormBackward0]
	1607400428912 -> 1607400429296
	1607400428912 [label=ConvolutionBackward0]
	1607400428192 -> 1607400428912
	1607400428192 [label=ReluBackward0]
	1607400427712 -> 1607400428192
	1607400427712 [label=CudnnBatchNormBackward0]
	1607400427424 -> 1607400427712
	1607400427424 [label=ConvolutionBackward0]
	1607400426848 -> 1607400427424
	1607400426848 [label=ReluBackward0]
	1607400426464 -> 1607400426848
	1607400426464 [label=CudnnBatchNormBackward0]
	1607400426320 -> 1607400426464
	1607400426320 [label=ConvolutionBackward0]
	1607400429488 -> 1607400426320
	1607400429488 [label=ReluBackward0]
	1607400425456 -> 1607400429488
	1607400425456 [label=AddBackward0]
	1607400425072 -> 1607400425456
	1607400425072 [label=CudnnBatchNormBackward0]
	1607400424640 -> 1607400425072
	1607400424640 [label=ConvolutionBackward0]
	1607400423968 -> 1607400424640
	1607400423968 [label=ReluBackward0]
	1607400423488 -> 1607400423968
	1607400423488 [label=CudnnBatchNormBackward0]
	1607400430112 -> 1607400423488
	1607400430112 [label=ConvolutionBackward0]
	1607400434960 -> 1607400430112
	1607400434960 [label=ReluBackward0]
	1607400430736 -> 1607400434960
	1607400430736 [label=CudnnBatchNormBackward0]
	1607400434288 -> 1607400430736
	1607400434288 [label=ConvolutionBackward0]
	1607400425216 -> 1607400434288
	1607400425216 [label=ReluBackward0]
	1607400431264 -> 1607400425216
	1607400431264 [label=AddBackward0]
	1607400431120 -> 1607400431264
	1607400431120 [label=CudnnBatchNormBackward0]
	1607400439760 -> 1607400431120
	1607400439760 [label=ConvolutionBackward0]
	1607400424016 -> 1607400439760
	1607400424016 [label=ReluBackward0]
	1607400427088 -> 1607400424016
	1607400427088 [label=CudnnBatchNormBackward0]
	1607255141408 -> 1607400427088
	1607255141408 [label=ConvolutionBackward0]
	1607400644736 -> 1607255141408
	1607400644736 [label=ReluBackward0]
	1607400645120 -> 1607400644736
	1607400645120 [label=CudnnBatchNormBackward0]
	1607400645408 -> 1607400645120
	1607400645408 [label=ConvolutionBackward0]
	1607400433712 -> 1607400645408
	1607400433712 [label=ReluBackward0]
	1607400646176 -> 1607400433712
	1607400646176 [label=AddBackward0]
	1607400646224 -> 1607400646176
	1607400646224 [label=CudnnBatchNormBackward0]
	1607400646848 -> 1607400646224
	1607400646848 [label=ConvolutionBackward0]
	1607400647424 -> 1607400646848
	1607400647424 [label=ReluBackward0]
	1607400647568 -> 1607400647424
	1607400647568 [label=CudnnBatchNormBackward0]
	1607400649728 -> 1607400647568
	1607400649728 [label=ConvolutionBackward0]
	1607400648432 -> 1607400649728
	1607400648432 [label=ReluBackward0]
	1607400645792 -> 1607400648432
	1607400645792 [label=CudnnBatchNormBackward0]
	1607400643296 -> 1607400645792
	1607400643296 [label=ConvolutionBackward0]
	1607400646368 -> 1607400643296
	1607400646368 [label=ReluBackward0]
	1607400652368 -> 1607400646368
	1607400652368 [label=AddBackward0]
	1607400640560 -> 1607400652368
	1607400640560 [label=CudnnBatchNormBackward0]
	1607400651888 -> 1607400640560
	1607400651888 [label=ConvolutionBackward0]
	1607400651360 -> 1607400651888
	1607400651360 [label=ReluBackward0]
	1607400651072 -> 1607400651360
	1607400651072 [label=CudnnBatchNormBackward0]
	1607400650304 -> 1607400651072
	1607400650304 [label=ConvolutionBackward0]
	1607400650880 -> 1607400650304
	1607400650880 [label=ReluBackward0]
	1607400649584 -> 1607400650880
	1607400649584 [label=CudnnBatchNormBackward0]
	1607400649920 -> 1607400649584
	1607400649920 [label=ConvolutionBackward0]
	1607400652416 -> 1607400649920
	1607400652416 [label=ReluBackward0]
	1607400648240 -> 1607400652416
	1607400648240 [label=AddBackward0]
	1607400648192 -> 1607400648240
	1607400648192 [label=CudnnBatchNormBackward0]
	1607400644256 -> 1607400648192
	1607400644256 [label=ConvolutionBackward0]
	1607400643680 -> 1607400644256
	1607400643680 [label=ReluBackward0]
	1607400637632 -> 1607400643680
	1607400637632 [label=CudnnBatchNormBackward0]
	1607400643104 -> 1607400637632
	1607400643104 [label=ConvolutionBackward0]
	1607400642624 -> 1607400643104
	1607400642624 [label=ReluBackward0]
	1607400642240 -> 1607400642624
	1607400642240 [label=CudnnBatchNormBackward0]
	1607400641904 -> 1607400642240
	1607400641904 [label=ConvolutionBackward0]
	1607400648960 -> 1607400641904
	1607400648960 [label=ReluBackward0]
	1607400641136 -> 1607400648960
	1607400641136 [label=AddBackward0]
	1607400640944 -> 1607400641136
	1607400640944 [label=CudnnBatchNormBackward0]
	1607400640464 -> 1607400640944
	1607400640464 [label=ConvolutionBackward0]
	1607400640032 -> 1607400640464
	1607400640032 [label=ReluBackward0]
	1607400639744 -> 1607400640032
	1607400639744 [label=CudnnBatchNormBackward0]
	1607400639408 -> 1607400639744
	1607400639408 [label=ConvolutionBackward0]
	1607400638880 -> 1607400639408
	1607400638880 [label=ReluBackward0]
	1607400638592 -> 1607400638880
	1607400638592 [label=CudnnBatchNormBackward0]
	1607400638256 -> 1607400638592
	1607400638256 [label=ConvolutionBackward0]
	1607400641088 -> 1607400638256
	1607400641088 [label=ReluBackward0]
	1607400637440 -> 1607400641088
	1607400637440 [label=AddBackward0]
	1607400637248 -> 1607400637440
	1607400637248 [label=CudnnBatchNormBackward0]
	1607400636816 -> 1607400637248
	1607400636816 [label=ConvolutionBackward0]
	1607400637776 -> 1607400636816
	1607400637776 [label=ReluBackward0]
	1607400739440 -> 1607400637776
	1607400739440 [label=CudnnBatchNormBackward0]
	1607400745008 -> 1607400739440
	1607400745008 [label=ConvolutionBackward0]
	1607400744672 -> 1607400745008
	1607400744672 [label=ReluBackward0]
	1607400745536 -> 1607400744672
	1607400745536 [label=CudnnBatchNormBackward0]
	1607400745344 -> 1607400745536
	1607400745344 [label=ConvolutionBackward0]
	1607400637296 -> 1607400745344
	1607400637296 [label=ReluBackward0]
	1607400744480 -> 1607400637296
	1607400744480 [label=AddBackward0]
	1607400744144 -> 1607400744480
	1607400744144 [label=CudnnBatchNormBackward0]
	1607400743856 -> 1607400744144
	1607400743856 [label=ConvolutionBackward0]
	1607400743328 -> 1607400743856
	1607400743328 [label=ReluBackward0]
	1607400742896 -> 1607400743328
	1607400742896 [label=CudnnBatchNormBackward0]
	1607400742704 -> 1607400742896
	1607400742704 [label=ConvolutionBackward0]
	1607400742272 -> 1607400742704
	1607400742272 [label=ReluBackward0]
	1607400741696 -> 1607400742272
	1607400741696 [label=CudnnBatchNormBackward0]
	1607400741504 -> 1607400741696
	1607400741504 [label=ConvolutionBackward0]
	1607400744384 -> 1607400741504
	1607400744384 [label=ReluBackward0]
	1607400740736 -> 1607400744384
	1607400740736 [label=AddBackward0]
	1607400740352 -> 1607400740736
	1607400740352 [label=CudnnBatchNormBackward0]
	1607400740016 -> 1607400740352
	1607400740016 [label=ConvolutionBackward0]
	1607400739584 -> 1607400740016
	1607400739584 [label=ReluBackward0]
	1607400739104 -> 1607400739584
	1607400739104 [label=CudnnBatchNormBackward0]
	1607400738912 -> 1607400739104
	1607400738912 [label=ConvolutionBackward0]
	1607400738336 -> 1607400738912
	1607400738336 [label=ReluBackward0]
	1607400738048 -> 1607400738336
	1607400738048 [label=CudnnBatchNormBackward0]
	1607400737712 -> 1607400738048
	1607400737712 [label=ConvolutionBackward0]
	1607400740496 -> 1607400737712
	1607400740496 [label=ReluBackward0]
	1607400736992 -> 1607400740496
	1607400736992 [label=AddBackward0]
	1607400736704 -> 1607400736992
	1607400736704 [label=CudnnBatchNormBackward0]
	1607400736368 -> 1607400736704
	1607400736368 [label=ConvolutionBackward0]
	1607400735744 -> 1607400736368
	1607400735744 [label=ReluBackward0]
	1607400735360 -> 1607400735744
	1607400735360 [label=CudnnBatchNormBackward0]
	1607400735024 -> 1607400735360
	1607400735024 [label=ConvolutionBackward0]
	1607400745728 -> 1607400735024
	1607400745728 [label=ReluBackward0]
	1607400745872 -> 1607400745728
	1607400745872 [label=CudnnBatchNormBackward0]
	1607400745968 -> 1607400745872
	1607400745968 [label=ConvolutionBackward0]
	1607400736896 -> 1607400745968
	1607400736896 [label=ReluBackward0]
	1607400746256 -> 1607400736896
	1607400746256 [label=AddBackward0]
	1607400746352 -> 1607400746256
	1607400746352 [label=CudnnBatchNormBackward0]
	1607400746496 -> 1607400746352
	1607400746496 [label=ConvolutionBackward0]
	1607400746688 -> 1607400746496
	1607400746688 [label=ReluBackward0]
	1607400746832 -> 1607400746688
	1607400746832 [label=CudnnBatchNormBackward0]
	1607400746928 -> 1607400746832
	1607400746928 [label=ConvolutionBackward0]
	1607400747120 -> 1607400746928
	1607400747120 [label=ReluBackward0]
	1607400747264 -> 1607400747120
	1607400747264 [label=CudnnBatchNormBackward0]
	1607400747360 -> 1607400747264
	1607400747360 [label=ConvolutionBackward0]
	1607400746304 -> 1607400747360
	1607400746304 [label=ReluBackward0]
	1607400747648 -> 1607400746304
	1607400747648 [label=AddBackward0]
	1607400747744 -> 1607400747648
	1607400747744 [label=CudnnBatchNormBackward0]
	1607400747888 -> 1607400747744
	1607400747888 [label=ConvolutionBackward0]
	1607400748080 -> 1607400747888
	1607400748080 [label=ReluBackward0]
	1607400748224 -> 1607400748080
	1607400748224 [label=CudnnBatchNormBackward0]
	1607400748320 -> 1607400748224
	1607400748320 [label=ConvolutionBackward0]
	1607400748512 -> 1607400748320
	1607400748512 [label=ReluBackward0]
	1607400748656 -> 1607400748512
	1607400748656 [label=CudnnBatchNormBackward0]
	1607400748752 -> 1607400748656
	1607400748752 [label=ConvolutionBackward0]
	1607400747696 -> 1607400748752
	1607400747696 [label=ReluBackward0]
	1607400749040 -> 1607400747696
	1607400749040 [label=AddBackward0]
	1607400749136 -> 1607400749040
	1607400749136 [label=CudnnBatchNormBackward0]
	1607400749280 -> 1607400749136
	1607400749280 [label=ConvolutionBackward0]
	1607400749472 -> 1607400749280
	1607400749472 [label=ReluBackward0]
	1607400749616 -> 1607400749472
	1607400749616 [label=CudnnBatchNormBackward0]
	1607400749712 -> 1607400749616
	1607400749712 [label=ConvolutionBackward0]
	1607400749904 -> 1607400749712
	1607400749904 [label=ReluBackward0]
	1607400750048 -> 1607400749904
	1607400750048 [label=CudnnBatchNormBackward0]
	1607400750144 -> 1607400750048
	1607400750144 [label=ConvolutionBackward0]
	1607400749088 -> 1607400750144
	1607400749088 [label=ReluBackward0]
	1607400750432 -> 1607400749088
	1607400750432 [label=AddBackward0]
	1607400750528 -> 1607400750432
	1607400750528 [label=CudnnBatchNormBackward0]
	1607400750672 -> 1607400750528
	1607400750672 [label=ConvolutionBackward0]
	1607400750864 -> 1607400750672
	1607400750864 [label=ReluBackward0]
	1607400751008 -> 1607400750864
	1607400751008 [label=CudnnBatchNormBackward0]
	1607400751056 -> 1607400751008
	1607400751056 [label=ConvolutionBackward0]
	1607400915200 -> 1607400751056
	1607400915200 [label=ReluBackward0]
	1607400915344 -> 1607400915200
	1607400915344 [label=CudnnBatchNormBackward0]
	1607400915440 -> 1607400915344
	1607400915440 [label=ConvolutionBackward0]
	1607400915632 -> 1607400915440
	1607400915632 [label=ReluBackward0]
	1607400915776 -> 1607400915632
	1607400915776 [label=AddBackward0]
	1607400915872 -> 1607400915776
	1607400915872 [label=CudnnBatchNormBackward0]
	1607400916016 -> 1607400915872
	1607400916016 [label=ConvolutionBackward0]
	1607400916208 -> 1607400916016
	1607400916208 [label=ReluBackward0]
	1607400916352 -> 1607400916208
	1607400916352 [label=CudnnBatchNormBackward0]
	1607400916448 -> 1607400916352
	1607400916448 [label=ConvolutionBackward0]
	1607400916640 -> 1607400916448
	1607400916640 [label=ReluBackward0]
	1607400916784 -> 1607400916640
	1607400916784 [label=CudnnBatchNormBackward0]
	1607400916880 -> 1607400916784
	1607400916880 [label=ConvolutionBackward0]
	1607400915824 -> 1607400916880
	1607400915824 [label=ReluBackward0]
	1607400917168 -> 1607400915824
	1607400917168 [label=AddBackward0]
	1607400917264 -> 1607400917168
	1607400917264 [label=CudnnBatchNormBackward0]
	1607400917408 -> 1607400917264
	1607400917408 [label=ConvolutionBackward0]
	1607400917600 -> 1607400917408
	1607400917600 [label=ReluBackward0]
	1607400917744 -> 1607400917600
	1607400917744 [label=CudnnBatchNormBackward0]
	1607400917840 -> 1607400917744
	1607400917840 [label=ConvolutionBackward0]
	1607400918032 -> 1607400917840
	1607400918032 [label=ReluBackward0]
	1607400918176 -> 1607400918032
	1607400918176 [label=CudnnBatchNormBackward0]
	1607400918272 -> 1607400918176
	1607400918272 [label=ConvolutionBackward0]
	1607400917216 -> 1607400918272
	1607400917216 [label=ReluBackward0]
	1607400918560 -> 1607400917216
	1607400918560 [label=AddBackward0]
	1607400918656 -> 1607400918560
	1607400918656 [label=CudnnBatchNormBackward0]
	1607400918800 -> 1607400918656
	1607400918800 [label=ConvolutionBackward0]
	1607400918992 -> 1607400918800
	1607400918992 [label=ReluBackward0]
	1607400919136 -> 1607400918992
	1607400919136 [label=CudnnBatchNormBackward0]
	1607400919232 -> 1607400919136
	1607400919232 [label=ConvolutionBackward0]
	1607400919424 -> 1607400919232
	1607400919424 [label=ReluBackward0]
	1607400919568 -> 1607400919424
	1607400919568 [label=CudnnBatchNormBackward0]
	1607400919664 -> 1607400919568
	1607400919664 [label=ConvolutionBackward0]
	1607400918608 -> 1607400919664
	1607400918608 [label=ReluBackward0]
	1607400919952 -> 1607400918608
	1607400919952 [label=AddBackward0]
	1607400920048 -> 1607400919952
	1607400920048 [label=CudnnBatchNormBackward0]
	1607400920192 -> 1607400920048
	1607400920192 [label=ConvolutionBackward0]
	1607400920384 -> 1607400920192
	1607400920384 [label=ReluBackward0]
	1607400920528 -> 1607400920384
	1607400920528 [label=CudnnBatchNormBackward0]
	1607400920624 -> 1607400920528
	1607400920624 [label=ConvolutionBackward0]
	1607400920816 -> 1607400920624
	1607400920816 [label=ReluBackward0]
	1607400920960 -> 1607400920816
	1607400920960 [label=CudnnBatchNormBackward0]
	1607400921056 -> 1607400920960
	1607400921056 [label=ConvolutionBackward0]
	1607400920000 -> 1607400921056
	1607400920000 [label=ReluBackward0]
	1607400921344 -> 1607400920000
	1607400921344 [label=AddBackward0]
	1607400921440 -> 1607400921344
	1607400921440 [label=CudnnBatchNormBackward0]
	1607400921584 -> 1607400921440
	1607400921584 [label=ConvolutionBackward0]
	1607400921776 -> 1607400921584
	1607400921776 [label=ReluBackward0]
	1607400921920 -> 1607400921776
	1607400921920 [label=CudnnBatchNormBackward0]
	1607400922016 -> 1607400921920
	1607400922016 [label=ConvolutionBackward0]
	1607400922208 -> 1607400922016
	1607400922208 [label=ReluBackward0]
	1607400922352 -> 1607400922208
	1607400922352 [label=CudnnBatchNormBackward0]
	1607400922448 -> 1607400922352
	1607400922448 [label=ConvolutionBackward0]
	1607400921392 -> 1607400922448
	1607400921392 [label=ReluBackward0]
	1607400922736 -> 1607400921392
	1607400922736 [label=AddBackward0]
	1607400922832 -> 1607400922736
	1607400922832 [label=CudnnBatchNormBackward0]
	1607400922976 -> 1607400922832
	1607400922976 [label=ConvolutionBackward0]
	1607400923168 -> 1607400922976
	1607400923168 [label=ReluBackward0]
	1607400923312 -> 1607400923168
	1607400923312 [label=CudnnBatchNormBackward0]
	1607400923408 -> 1607400923312
	1607400923408 [label=ConvolutionBackward0]
	1607400923600 -> 1607400923408
	1607400923600 [label=ReluBackward0]
	1607400923744 -> 1607400923600
	1607400923744 [label=CudnnBatchNormBackward0]
	1607400923840 -> 1607400923744
	1607400923840 [label=ConvolutionBackward0]
	1607400922784 -> 1607400923840
	1607400922784 [label=ReluBackward0]
	1607400924128 -> 1607400922784
	1607400924128 [label=AddBackward0]
	1607400924224 -> 1607400924128
	1607400924224 [label=CudnnBatchNormBackward0]
	1607400924368 -> 1607400924224
	1607400924368 [label=ConvolutionBackward0]
	1607400924560 -> 1607400924368
	1607400924560 [label=ReluBackward0]
	1607400924704 -> 1607400924560
	1607400924704 [label=CudnnBatchNormBackward0]
	1607400924800 -> 1607400924704
	1607400924800 [label=ConvolutionBackward0]
	1607400924992 -> 1607400924800
	1607400924992 [label=ReluBackward0]
	1607400925136 -> 1607400924992
	1607400925136 [label=CudnnBatchNormBackward0]
	1607400925232 -> 1607400925136
	1607400925232 [label=ConvolutionBackward0]
	1607400924176 -> 1607400925232
	1607400924176 [label=ReluBackward0]
	1607400925520 -> 1607400924176
	1607400925520 [label=AddBackward0]
	1607400925616 -> 1607400925520
	1607400925616 [label=CudnnBatchNormBackward0]
	1607400925760 -> 1607400925616
	1607400925760 [label=ConvolutionBackward0]
	1607400925952 -> 1607400925760
	1607400925952 [label=ReluBackward0]
	1607400926096 -> 1607400925952
	1607400926096 [label=CudnnBatchNormBackward0]
	1607400926192 -> 1607400926096
	1607400926192 [label=ConvolutionBackward0]
	1607400926384 -> 1607400926192
	1607400926384 [label=ReluBackward0]
	1607400926528 -> 1607400926384
	1607400926528 [label=CudnnBatchNormBackward0]
	1607400926624 -> 1607400926528
	1607400926624 [label=ConvolutionBackward0]
	1607400926816 -> 1607400926624
	1607400926816 [label=ReluBackward0]
	1607400926960 -> 1607400926816
	1607400926960 [label=AddBackward0]
	1607400927056 -> 1607400926960
	1607400927056 [label=CudnnBatchNormBackward0]
	1607400927200 -> 1607400927056
	1607400927200 [label=ConvolutionBackward0]
	1607400927392 -> 1607400927200
	1607400927392 [label=ReluBackward0]
	1607400927536 -> 1607400927392
	1607400927536 [label=CudnnBatchNormBackward0]
	1607400927632 -> 1607400927536
	1607400927632 [label=ConvolutionBackward0]
	1607400927824 -> 1607400927632
	1607400927824 [label=ReluBackward0]
	1607400927968 -> 1607400927824
	1607400927968 [label=CudnnBatchNormBackward0]
	1607400928064 -> 1607400927968
	1607400928064 [label=ConvolutionBackward0]
	1607400927008 -> 1607400928064
	1607400927008 [label=ReluBackward0]
	1607400928352 -> 1607400927008
	1607400928352 [label=AddBackward0]
	1607400928448 -> 1607400928352
	1607400928448 [label=CudnnBatchNormBackward0]
	1607400928592 -> 1607400928448
	1607400928592 [label=ConvolutionBackward0]
	1607400928784 -> 1607400928592
	1607400928784 [label=ReluBackward0]
	1607400928928 -> 1607400928784
	1607400928928 [label=CudnnBatchNormBackward0]
	1607400929024 -> 1607400928928
	1607400929024 [label=ConvolutionBackward0]
	1607400929216 -> 1607400929024
	1607400929216 [label=ReluBackward0]
	1607400929360 -> 1607400929216
	1607400929360 [label=CudnnBatchNormBackward0]
	1607400929456 -> 1607400929360
	1607400929456 [label=ConvolutionBackward0]
	1607400928400 -> 1607400929456
	1607400928400 [label=ReluBackward0]
	1607400929744 -> 1607400928400
	1607400929744 [label=AddBackward0]
	1607400929840 -> 1607400929744
	1607400929840 [label=CudnnBatchNormBackward0]
	1607400929984 -> 1607400929840
	1607400929984 [label=ConvolutionBackward0]
	1607400930176 -> 1607400929984
	1607400930176 [label=ReluBackward0]
	1607400930320 -> 1607400930176
	1607400930320 [label=CudnnBatchNormBackward0]
	1607400930416 -> 1607400930320
	1607400930416 [label=ConvolutionBackward0]
	1607400930608 -> 1607400930416
	1607400930608 [label=ReluBackward0]
	1607400930752 -> 1607400930608
	1607400930752 [label=CudnnBatchNormBackward0]
	1607400930848 -> 1607400930752
	1607400930848 [label=ConvolutionBackward0]
	1607400931040 -> 1607400930848
	1607400931040 [label=MaxPool2DWithIndicesBackward0]
	1607400931184 -> 1607400931040
	1607400931184 [label=ReluBackward0]
	1607400931280 -> 1607400931184
	1607400931280 [label=CudnnBatchNormBackward0]
	1607400931088 -> 1607400931280
	1607400931088 [label=ConvolutionBackward0]
	1607400866096 -> 1607400931088
	1607167906656 [label="conv1.weight
 (64, 3, 7, 7)" fillcolor=lightblue]
	1607167906656 -> 1607400866096
	1607400866096 [label=AccumulateGrad]
	1607400865904 -> 1607400931280
	1607167906736 [label="bn1.weight
 (64)" fillcolor=lightblue]
	1607167906736 -> 1607400865904
	1607400865904 [label=AccumulateGrad]
	1607400865856 -> 1607400931280
	1607167906576 [label="bn1.bias
 (64)" fillcolor=lightblue]
	1607167906576 -> 1607400865856
	1607400865856 [label=AccumulateGrad]
	1607400930992 -> 1607400930848
	1607167905456 [label="layer1.0.conv1.weight
 (64, 64, 1, 1)" fillcolor=lightblue]
	1607167905456 -> 1607400930992
	1607400930992 [label=AccumulateGrad]
	1607400930800 -> 1607400930752
	1607167905376 [label="layer1.0.bn1.weight
 (64)" fillcolor=lightblue]
	1607167905376 -> 1607400930800
	1607400930800 [label=AccumulateGrad]
	1607400930656 -> 1607400930752
	1607167905296 [label="layer1.0.bn1.bias
 (64)" fillcolor=lightblue]
	1607167905296 -> 1607400930656
	1607400930656 [label=AccumulateGrad]
	1607400930560 -> 1607400930416
	1607167904736 [label="layer1.0.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1607167904736 -> 1607400930560
	1607400930560 [label=AccumulateGrad]
	1607400930368 -> 1607400930320
	1607167904816 [label="layer1.0.bn2.weight
 (64)" fillcolor=lightblue]
	1607167904816 -> 1607400930368
	1607400930368 [label=AccumulateGrad]
	1607400930224 -> 1607400930320
	1607167904656 [label="layer1.0.bn2.bias
 (64)" fillcolor=lightblue]
	1607167904656 -> 1607400930224
	1607400930224 [label=AccumulateGrad]
	1607400930128 -> 1607400929984
	1607167904176 [label="layer1.0.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1607167904176 -> 1607400930128
	1607400930128 [label=AccumulateGrad]
	1607400929936 -> 1607400929840
	1607167904096 [label="layer1.0.bn3.weight
 (256)" fillcolor=lightblue]
	1607167904096 -> 1607400929936
	1607400929936 [label=AccumulateGrad]
	1607400929888 -> 1607400929840
	1607167904016 [label="layer1.0.bn3.bias
 (256)" fillcolor=lightblue]
	1607167904016 -> 1607400929888
	1607400929888 [label=AccumulateGrad]
	1607400929792 -> 1607400929744
	1607400929792 [label=CudnnBatchNormBackward0]
	1607400930704 -> 1607400929792
	1607400930704 [label=ConvolutionBackward0]
	1607400931040 -> 1607400930704
	1607400930512 -> 1607400930704
	1607167906016 [label="layer1.0.downsample.0.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1607167906016 -> 1607400930512
	1607400930512 [label=AccumulateGrad]
	1607400930272 -> 1607400929792
	1607167905936 [label="layer1.0.downsample.1.weight
 (256)" fillcolor=lightblue]
	1607167905936 -> 1607400930272
	1607400930272 [label=AccumulateGrad]
	1607400930032 -> 1607400929792
	1607167906176 [label="layer1.0.downsample.1.bias
 (256)" fillcolor=lightblue]
	1607167906176 -> 1607400930032
	1607400930032 [label=AccumulateGrad]
	1607400929648 -> 1607400929456
	1607167903776 [label="layer1.1.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1607167903776 -> 1607400929648
	1607400929648 [label=AccumulateGrad]
	1607400929408 -> 1607400929360
	1607167903696 [label="layer1.1.bn1.weight
 (64)" fillcolor=lightblue]
	1607167903696 -> 1607400929408
	1607400929408 [label=AccumulateGrad]
	1607400929264 -> 1607400929360
	1607167903456 [label="layer1.1.bn1.bias
 (64)" fillcolor=lightblue]
	1607167903456 -> 1607400929264
	1607400929264 [label=AccumulateGrad]
	1607400929168 -> 1607400929024
	1607167902736 [label="layer1.1.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1607167902736 -> 1607400929168
	1607400929168 [label=AccumulateGrad]
	1607400928976 -> 1607400928928
	1607167902816 [label="layer1.1.bn2.weight
 (64)" fillcolor=lightblue]
	1607167902816 -> 1607400928976
	1607400928976 [label=AccumulateGrad]
	1607400928832 -> 1607400928928
	1607167902656 [label="layer1.1.bn2.bias
 (64)" fillcolor=lightblue]
	1607167902656 -> 1607400928832
	1607400928832 [label=AccumulateGrad]
	1607400928736 -> 1607400928592
	1607167902176 [label="layer1.1.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1607167902176 -> 1607400928736
	1607400928736 [label=AccumulateGrad]
	1607400928544 -> 1607400928448
	1607167902096 [label="layer1.1.bn3.weight
 (256)" fillcolor=lightblue]
	1607167902096 -> 1607400928544
	1607400928544 [label=AccumulateGrad]
	1607400928496 -> 1607400928448
	1607167902016 [label="layer1.1.bn3.bias
 (256)" fillcolor=lightblue]
	1607167902016 -> 1607400928496
	1607400928496 [label=AccumulateGrad]
	1607400928400 -> 1607400928352
	1607400928256 -> 1607400928064
	1607167877808 [label="layer1.2.conv1.weight
 (64, 256, 1, 1)" fillcolor=lightblue]
	1607167877808 -> 1607400928256
	1607400928256 [label=AccumulateGrad]
	1607400928016 -> 1607400927968
	1607167877728 [label="layer1.2.bn1.weight
 (64)" fillcolor=lightblue]
	1607167877728 -> 1607400928016
	1607400928016 [label=AccumulateGrad]
	1607400927872 -> 1607400927968
	1607167877648 [label="layer1.2.bn1.bias
 (64)" fillcolor=lightblue]
	1607167877648 -> 1607400927872
	1607400927872 [label=AccumulateGrad]
	1607400927776 -> 1607400927632
	1607167877408 [label="layer1.2.conv2.weight
 (64, 64, 3, 3)" fillcolor=lightblue]
	1607167877408 -> 1607400927776
	1607400927776 [label=AccumulateGrad]
	1607400927584 -> 1607400927536
	1607167883728 [label="layer1.2.bn2.weight
 (64)" fillcolor=lightblue]
	1607167883728 -> 1607400927584
	1607400927584 [label=AccumulateGrad]
	1607400927440 -> 1607400927536
	1607167877328 [label="layer1.2.bn2.bias
 (64)" fillcolor=lightblue]
	1607167877328 -> 1607400927440
	1607400927440 [label=AccumulateGrad]
	1607400927344 -> 1607400927200
	1607167883408 [label="layer1.2.conv3.weight
 (256, 64, 1, 1)" fillcolor=lightblue]
	1607167883408 -> 1607400927344
	1607400927344 [label=AccumulateGrad]
	1607400927152 -> 1607400927056
	1607167877088 [label="layer1.2.bn3.weight
 (256)" fillcolor=lightblue]
	1607167877088 -> 1607400927152
	1607400927152 [label=AccumulateGrad]
	1607400927104 -> 1607400927056
	1607167877008 [label="layer1.2.bn3.bias
 (256)" fillcolor=lightblue]
	1607167877008 -> 1607400927104
	1607400927104 [label=AccumulateGrad]
	1607400927008 -> 1607400926960
	1607400926768 -> 1607400926624
	1607167876608 [label="layer2.0.conv1.weight
 (128, 256, 1, 1)" fillcolor=lightblue]
	1607167876608 -> 1607400926768
	1607400926768 [label=AccumulateGrad]
	1607400926576 -> 1607400926528
	1607167876528 [label="layer2.0.bn1.weight
 (128)" fillcolor=lightblue]
	1607167876528 -> 1607400926576
	1607400926576 [label=AccumulateGrad]
	1607400926432 -> 1607400926528
	1607167882848 [label="layer2.0.bn1.bias
 (128)" fillcolor=lightblue]
	1607167882848 -> 1607400926432
	1607400926432 [label=AccumulateGrad]
	1607400926336 -> 1607400926192
	1607167876048 [label="layer2.0.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607167876048 -> 1607400926336
	1607400926336 [label=AccumulateGrad]
	1607400926144 -> 1607400926096
	1607167876128 [label="layer2.0.bn2.weight
 (128)" fillcolor=lightblue]
	1607167876128 -> 1607400926144
	1607400926144 [label=AccumulateGrad]
	1607400926000 -> 1607400926096
	1607167882368 [label="layer2.0.bn2.bias
 (128)" fillcolor=lightblue]
	1607167882368 -> 1607400926000
	1607400926000 [label=AccumulateGrad]
	1607400925904 -> 1607400925760
	1607167875808 [label="layer2.0.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607167875808 -> 1607400925904
	1607400925904 [label=AccumulateGrad]
	1607400925712 -> 1607400925616
	1607167875728 [label="layer2.0.bn3.weight
 (512)" fillcolor=lightblue]
	1607167875728 -> 1607400925712
	1607400925712 [label=AccumulateGrad]
	1607400925664 -> 1607400925616
	1607167882048 [label="layer2.0.bn3.bias
 (512)" fillcolor=lightblue]
	1607167882048 -> 1607400925664
	1607400925664 [label=AccumulateGrad]
	1607400925568 -> 1607400925520
	1607400925568 [label=CudnnBatchNormBackward0]
	1607400926480 -> 1607400925568
	1607400926480 [label=ConvolutionBackward0]
	1607400926816 -> 1607400926480
	1607400926288 -> 1607400926480
	1607167883088 [label="layer2.0.downsample.0.weight
 (512, 256, 1, 1)" fillcolor=lightblue]
	1607167883088 -> 1607400926288
	1607400926288 [label=AccumulateGrad]
	1607400926048 -> 1607400925568
	1607167876768 [label="layer2.0.downsample.1.weight
 (512)" fillcolor=lightblue]
	1607167876768 -> 1607400926048
	1607400926048 [label=AccumulateGrad]
	1607400925808 -> 1607400925568
	1607167876688 [label="layer2.0.downsample.1.bias
 (512)" fillcolor=lightblue]
	1607167876688 -> 1607400925808
	1607400925808 [label=AccumulateGrad]
	1607400925424 -> 1607400925232
	1607167881808 [label="layer2.1.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1607167881808 -> 1607400925424
	1607400925424 [label=AccumulateGrad]
	1607400925184 -> 1607400925136
	1607167875488 [label="layer2.1.bn1.weight
 (128)" fillcolor=lightblue]
	1607167875488 -> 1607400925184
	1607400925184 [label=AccumulateGrad]
	1607400925040 -> 1607400925136
	1607167875408 [label="layer2.1.bn1.bias
 (128)" fillcolor=lightblue]
	1607167875408 -> 1607400925040
	1607400925040 [label=AccumulateGrad]
	1607400924944 -> 1607400924800
	1607167875168 [label="layer2.1.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607167875168 -> 1607400924944
	1607400924944 [label=AccumulateGrad]
	1607400924752 -> 1607400924704
	1607167881488 [label="layer2.1.bn2.weight
 (128)" fillcolor=lightblue]
	1607167881488 -> 1607400924752
	1607400924752 [label=AccumulateGrad]
	1607400924608 -> 1607400924704
	1607167875088 [label="layer2.1.bn2.bias
 (128)" fillcolor=lightblue]
	1607167875088 -> 1607400924608
	1607400924608 [label=AccumulateGrad]
	1607400924512 -> 1607400924368
	1607167881168 [label="layer2.1.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607167881168 -> 1607400924512
	1607400924512 [label=AccumulateGrad]
	1607400924320 -> 1607400924224
	1607167874848 [label="layer2.1.bn3.weight
 (512)" fillcolor=lightblue]
	1607167874848 -> 1607400924320
	1607400924320 [label=AccumulateGrad]
	1607400924272 -> 1607400924224
	1607167874768 [label="layer2.1.bn3.bias
 (512)" fillcolor=lightblue]
	1607167874768 -> 1607400924272
	1607400924272 [label=AccumulateGrad]
	1607400924176 -> 1607400924128
	1607400924032 -> 1607400923840
	1607167880848 [label="layer2.2.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1607167880848 -> 1607400924032
	1607400924032 [label=AccumulateGrad]
	1607400923792 -> 1607400923744
	1607167874528 [label="layer2.2.bn1.weight
 (128)" fillcolor=lightblue]
	1607167874528 -> 1607400923792
	1607400923792 [label=AccumulateGrad]
	1607400923648 -> 1607400923744
	1607167874448 [label="layer2.2.bn1.bias
 (128)" fillcolor=lightblue]
	1607167874448 -> 1607400923648
	1607400923648 [label=AccumulateGrad]
	1607400923552 -> 1607400923408
	1607167874048 [label="layer2.2.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607167874048 -> 1607400923552
	1607400923552 [label=AccumulateGrad]
	1607400923360 -> 1607400923312
	1607167880528 [label="layer2.2.bn2.weight
 (128)" fillcolor=lightblue]
	1607167880528 -> 1607400923360
	1607400923360 [label=AccumulateGrad]
	1607400923216 -> 1607400923312
	1607167873968 [label="layer2.2.bn2.bias
 (128)" fillcolor=lightblue]
	1607167873968 -> 1607400923216
	1607400923216 [label=AccumulateGrad]
	1607400923120 -> 1607400922976
	1607167880448 [label="layer2.2.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607167880448 -> 1607400923120
	1607400923120 [label=AccumulateGrad]
	1607400922928 -> 1607400922832
	1607167880368 [label="layer2.2.bn3.weight
 (512)" fillcolor=lightblue]
	1607167880368 -> 1607400922928
	1607400922928 [label=AccumulateGrad]
	1607400922880 -> 1607400922832
	1607167873728 [label="layer2.2.bn3.bias
 (512)" fillcolor=lightblue]
	1607167873728 -> 1607400922880
	1607400922880 [label=AccumulateGrad]
	1607400922784 -> 1607400922736
	1607400922640 -> 1607400922448
	1607167880128 [label="layer2.3.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1607167880128 -> 1607400922640
	1607400922640 [label=AccumulateGrad]
	1607400922400 -> 1607400922352
	1607167873488 [label="layer2.3.bn1.weight
 (128)" fillcolor=lightblue]
	1607167873488 -> 1607400922400
	1607400922400 [label=AccumulateGrad]
	1607400922256 -> 1607400922352
	1607167880048 [label="layer2.3.bn1.bias
 (128)" fillcolor=lightblue]
	1607167880048 -> 1607400922256
	1607400922256 [label=AccumulateGrad]
	1607400922160 -> 1607400922016
	1607167879648 [label="layer2.3.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607167879648 -> 1607400922160
	1607400922160 [label=AccumulateGrad]
	1607400921968 -> 1607400921920
	1607167873008 [label="layer2.3.bn2.weight
 (128)" fillcolor=lightblue]
	1607167873008 -> 1607400921968
	1607400921968 [label=AccumulateGrad]
	1607400921824 -> 1607400921920
	1607167879568 [label="layer2.3.bn2.bias
 (128)" fillcolor=lightblue]
	1607167879568 -> 1607400921824
	1607400921824 [label=AccumulateGrad]
	1607400921728 -> 1607400921584
	1607167872688 [label="layer2.3.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607167872688 -> 1607400921728
	1607400921728 [label=AccumulateGrad]
	1607400921536 -> 1607400921440
	1607167879328 [label="layer2.3.bn3.weight
 (512)" fillcolor=lightblue]
	1607167879328 -> 1607400921536
	1607400921536 [label=AccumulateGrad]
	1607400921488 -> 1607400921440
	1607167879248 [label="layer2.3.bn3.bias
 (512)" fillcolor=lightblue]
	1607167879248 -> 1607400921488
	1607400921488 [label=AccumulateGrad]
	1607400921392 -> 1607400921344
	1607400921248 -> 1607400921056
	1607167872368 [label="layer2.4.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1607167872368 -> 1607400921248
	1607400921248 [label=AccumulateGrad]
	1607400921008 -> 1607400920960
	1607167879008 [label="layer2.4.bn1.weight
 (128)" fillcolor=lightblue]
	1607167879008 -> 1607400921008
	1607400921008 [label=AccumulateGrad]
	1607400920864 -> 1607400920960
	1607167878848 [label="layer2.4.bn1.bias
 (128)" fillcolor=lightblue]
	1607167878848 -> 1607400920864
	1607400920864 [label=AccumulateGrad]
	1607400920768 -> 1607400920624
	1607167877968 [label="layer2.4.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607167877968 -> 1607400920768
	1607400920768 [label=AccumulateGrad]
	1607400920576 -> 1607400920528
	1607167869008 [label="layer2.4.bn2.weight
 (128)" fillcolor=lightblue]
	1607167869008 -> 1607400920576
	1607400920576 [label=AccumulateGrad]
	1607400920432 -> 1607400920528
	1607167877888 [label="layer2.4.bn2.bias
 (128)" fillcolor=lightblue]
	1607167877888 -> 1607400920432
	1607400920432 [label=AccumulateGrad]
	1607400920336 -> 1607400920192
	1607290134816 [label="layer2.4.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607290134816 -> 1607400920336
	1607400920336 [label=AccumulateGrad]
	1607400920144 -> 1607400920048
	1607290134896 [label="layer2.4.bn3.weight
 (512)" fillcolor=lightblue]
	1607290134896 -> 1607400920144
	1607400920144 [label=AccumulateGrad]
	1607400920096 -> 1607400920048
	1607290134976 [label="layer2.4.bn3.bias
 (512)" fillcolor=lightblue]
	1607290134976 -> 1607400920096
	1607400920096 [label=AccumulateGrad]
	1607400920000 -> 1607400919952
	1607400919856 -> 1607400919664
	1607290135456 [label="layer2.5.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1607290135456 -> 1607400919856
	1607400919856 [label=AccumulateGrad]
	1607400919616 -> 1607400919568
	1607290135536 [label="layer2.5.bn1.weight
 (128)" fillcolor=lightblue]
	1607290135536 -> 1607400919616
	1607400919616 [label=AccumulateGrad]
	1607400919472 -> 1607400919568
	1607290135616 [label="layer2.5.bn1.bias
 (128)" fillcolor=lightblue]
	1607290135616 -> 1607400919472
	1607400919472 [label=AccumulateGrad]
	1607400919376 -> 1607400919232
	1607290136176 [label="layer2.5.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607290136176 -> 1607400919376
	1607400919376 [label=AccumulateGrad]
	1607400919184 -> 1607400919136
	1607290136096 [label="layer2.5.bn2.weight
 (128)" fillcolor=lightblue]
	1607290136096 -> 1607400919184
	1607400919184 [label=AccumulateGrad]
	1607400919040 -> 1607400919136
	1607290136256 [label="layer2.5.bn2.bias
 (128)" fillcolor=lightblue]
	1607290136256 -> 1607400919040
	1607400919040 [label=AccumulateGrad]
	1607400918944 -> 1607400918800
	1607290136736 [label="layer2.5.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607290136736 -> 1607400918944
	1607400918944 [label=AccumulateGrad]
	1607400918752 -> 1607400918656
	1607290136816 [label="layer2.5.bn3.weight
 (512)" fillcolor=lightblue]
	1607290136816 -> 1607400918752
	1607400918752 [label=AccumulateGrad]
	1607400918704 -> 1607400918656
	1607290136896 [label="layer2.5.bn3.bias
 (512)" fillcolor=lightblue]
	1607290136896 -> 1607400918704
	1607400918704 [label=AccumulateGrad]
	1607400918608 -> 1607400918560
	1607400918464 -> 1607400918272
	1607290137376 [label="layer2.6.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1607290137376 -> 1607400918464
	1607400918464 [label=AccumulateGrad]
	1607400918224 -> 1607400918176
	1607290137456 [label="layer2.6.bn1.weight
 (128)" fillcolor=lightblue]
	1607290137456 -> 1607400918224
	1607400918224 [label=AccumulateGrad]
	1607400918080 -> 1607400918176
	1607290137536 [label="layer2.6.bn1.bias
 (128)" fillcolor=lightblue]
	1607290137536 -> 1607400918080
	1607400918080 [label=AccumulateGrad]
	1607400917984 -> 1607400917840
	1607290138096 [label="layer2.6.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607290138096 -> 1607400917984
	1607400917984 [label=AccumulateGrad]
	1607400917792 -> 1607400917744
	1607290137856 [label="layer2.6.bn2.weight
 (128)" fillcolor=lightblue]
	1607290137856 -> 1607400917792
	1607400917792 [label=AccumulateGrad]
	1607400917648 -> 1607400917744
	1607290138016 [label="layer2.6.bn2.bias
 (128)" fillcolor=lightblue]
	1607290138016 -> 1607400917648
	1607400917648 [label=AccumulateGrad]
	1607400917552 -> 1607400917408
	1607290138576 [label="layer2.6.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607290138576 -> 1607400917552
	1607400917552 [label=AccumulateGrad]
	1607400917360 -> 1607400917264
	1607290138656 [label="layer2.6.bn3.weight
 (512)" fillcolor=lightblue]
	1607290138656 -> 1607400917360
	1607400917360 [label=AccumulateGrad]
	1607400917312 -> 1607400917264
	1607290138736 [label="layer2.6.bn3.bias
 (512)" fillcolor=lightblue]
	1607290138736 -> 1607400917312
	1607400917312 [label=AccumulateGrad]
	1607400917216 -> 1607400917168
	1607400917072 -> 1607400916880
	1607290139216 [label="layer2.7.conv1.weight
 (128, 512, 1, 1)" fillcolor=lightblue]
	1607290139216 -> 1607400917072
	1607400917072 [label=AccumulateGrad]
	1607400916832 -> 1607400916784
	1607290139296 [label="layer2.7.bn1.weight
 (128)" fillcolor=lightblue]
	1607290139296 -> 1607400916832
	1607400916832 [label=AccumulateGrad]
	1607400916688 -> 1607400916784
	1607290139376 [label="layer2.7.bn1.bias
 (128)" fillcolor=lightblue]
	1607290139376 -> 1607400916688
	1607400916688 [label=AccumulateGrad]
	1607400916592 -> 1607400916448
	1607290139936 [label="layer2.7.conv2.weight
 (128, 128, 3, 3)" fillcolor=lightblue]
	1607290139936 -> 1607400916592
	1607400916592 [label=AccumulateGrad]
	1607400916400 -> 1607400916352
	1607290139856 [label="layer2.7.bn2.weight
 (128)" fillcolor=lightblue]
	1607290139856 -> 1607400916400
	1607400916400 [label=AccumulateGrad]
	1607400916256 -> 1607400916352
	1607290140016 [label="layer2.7.bn2.bias
 (128)" fillcolor=lightblue]
	1607290140016 -> 1607400916256
	1607400916256 [label=AccumulateGrad]
	1607400916160 -> 1607400916016
	1607290140496 [label="layer2.7.conv3.weight
 (512, 128, 1, 1)" fillcolor=lightblue]
	1607290140496 -> 1607400916160
	1607400916160 [label=AccumulateGrad]
	1607400915968 -> 1607400915872
	1607290140576 [label="layer2.7.bn3.weight
 (512)" fillcolor=lightblue]
	1607290140576 -> 1607400915968
	1607400915968 [label=AccumulateGrad]
	1607400915920 -> 1607400915872
	1607290140656 [label="layer2.7.bn3.bias
 (512)" fillcolor=lightblue]
	1607290140656 -> 1607400915920
	1607400915920 [label=AccumulateGrad]
	1607400915824 -> 1607400915776
	1607400915584 -> 1607400915440
	1607290141776 [label="layer3.0.conv1.weight
 (256, 512, 1, 1)" fillcolor=lightblue]
	1607290141776 -> 1607400915584
	1607400915584 [label=AccumulateGrad]
	1607400915392 -> 1607400915344
	1607290141856 [label="layer3.0.bn1.weight
 (256)" fillcolor=lightblue]
	1607290141856 -> 1607400915392
	1607400915392 [label=AccumulateGrad]
	1607400915248 -> 1607400915344
	1607290141936 [label="layer3.0.bn1.bias
 (256)" fillcolor=lightblue]
	1607290141936 -> 1607400915248
	1607400915248 [label=AccumulateGrad]
	1607400915152 -> 1607400751056
	1607290142496 [label="layer3.0.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290142496 -> 1607400915152
	1607400915152 [label=AccumulateGrad]
	1607400750912 -> 1607400751008
	1607290142416 [label="layer3.0.bn2.weight
 (256)" fillcolor=lightblue]
	1607290142416 -> 1607400750912
	1607400750912 [label=AccumulateGrad]
	1607400915008 -> 1607400751008
	1607290142576 [label="layer3.0.bn2.bias
 (256)" fillcolor=lightblue]
	1607290142576 -> 1607400915008
	1607400915008 [label=AccumulateGrad]
	1607400750816 -> 1607400750672
	1607290421648 [label="layer3.0.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290421648 -> 1607400750816
	1607400750816 [label=AccumulateGrad]
	1607400750624 -> 1607400750528
	1607290421728 [label="layer3.0.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290421728 -> 1607400750624
	1607400750624 [label=AccumulateGrad]
	1607400750576 -> 1607400750528
	1607290421808 [label="layer3.0.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290421808 -> 1607400750576
	1607400750576 [label=AccumulateGrad]
	1607400750480 -> 1607400750432
	1607400750480 [label=CudnnBatchNormBackward0]
	1607400750960 -> 1607400750480
	1607400750960 [label=ConvolutionBackward0]
	1607400915632 -> 1607400750960
	1607400915104 -> 1607400750960
	1607290141136 [label="layer3.0.downsample.0.weight
 (1024, 512, 1, 1)" fillcolor=lightblue]
	1607290141136 -> 1607400915104
	1607400915104 [label=AccumulateGrad]
	1607400750768 -> 1607400750480
	1607290141216 [label="layer3.0.downsample.1.weight
 (1024)" fillcolor=lightblue]
	1607290141216 -> 1607400750768
	1607400750768 [label=AccumulateGrad]
	1607400750720 -> 1607400750480
	1607290141296 [label="layer3.0.downsample.1.bias
 (1024)" fillcolor=lightblue]
	1607290141296 -> 1607400750720
	1607400750720 [label=AccumulateGrad]
	1607400750336 -> 1607400750144
	1607290422208 [label="layer3.1.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290422208 -> 1607400750336
	1607400750336 [label=AccumulateGrad]
	1607400750096 -> 1607400750048
	1607290422288 [label="layer3.1.bn1.weight
 (256)" fillcolor=lightblue]
	1607290422288 -> 1607400750096
	1607400750096 [label=AccumulateGrad]
	1607400749952 -> 1607400750048
	1607290422368 [label="layer3.1.bn1.bias
 (256)" fillcolor=lightblue]
	1607290422368 -> 1607400749952
	1607400749952 [label=AccumulateGrad]
	1607400749856 -> 1607400749712
	1607290422848 [label="layer3.1.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290422848 -> 1607400749856
	1607400749856 [label=AccumulateGrad]
	1607400749664 -> 1607400749616
	1607290422768 [label="layer3.1.bn2.weight
 (256)" fillcolor=lightblue]
	1607290422768 -> 1607400749664
	1607400749664 [label=AccumulateGrad]
	1607400749520 -> 1607400749616
	1607290422928 [label="layer3.1.bn2.bias
 (256)" fillcolor=lightblue]
	1607290422928 -> 1607400749520
	1607400749520 [label=AccumulateGrad]
	1607400749424 -> 1607400749280
	1607290423408 [label="layer3.1.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290423408 -> 1607400749424
	1607400749424 [label=AccumulateGrad]
	1607400749232 -> 1607400749136
	1607290423488 [label="layer3.1.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290423488 -> 1607400749232
	1607400749232 [label=AccumulateGrad]
	1607400749184 -> 1607400749136
	1607290423568 [label="layer3.1.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290423568 -> 1607400749184
	1607400749184 [label=AccumulateGrad]
	1607400749088 -> 1607400749040
	1607400748944 -> 1607400748752
	1607290424048 [label="layer3.2.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290424048 -> 1607400748944
	1607400748944 [label=AccumulateGrad]
	1607400748704 -> 1607400748656
	1607290424128 [label="layer3.2.bn1.weight
 (256)" fillcolor=lightblue]
	1607290424128 -> 1607400748704
	1607400748704 [label=AccumulateGrad]
	1607400748560 -> 1607400748656
	1607290424208 [label="layer3.2.bn1.bias
 (256)" fillcolor=lightblue]
	1607290424208 -> 1607400748560
	1607400748560 [label=AccumulateGrad]
	1607400748464 -> 1607400748320
	1607290424768 [label="layer3.2.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290424768 -> 1607400748464
	1607400748464 [label=AccumulateGrad]
	1607400748272 -> 1607400748224
	1607290424688 [label="layer3.2.bn2.weight
 (256)" fillcolor=lightblue]
	1607290424688 -> 1607400748272
	1607400748272 [label=AccumulateGrad]
	1607400748128 -> 1607400748224
	1607290424848 [label="layer3.2.bn2.bias
 (256)" fillcolor=lightblue]
	1607290424848 -> 1607400748128
	1607400748128 [label=AccumulateGrad]
	1607400748032 -> 1607400747888
	1607290425328 [label="layer3.2.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290425328 -> 1607400748032
	1607400748032 [label=AccumulateGrad]
	1607400747840 -> 1607400747744
	1607290425408 [label="layer3.2.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290425408 -> 1607400747840
	1607400747840 [label=AccumulateGrad]
	1607400747792 -> 1607400747744
	1607290425488 [label="layer3.2.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290425488 -> 1607400747792
	1607400747792 [label=AccumulateGrad]
	1607400747696 -> 1607400747648
	1607400747552 -> 1607400747360
	1607290425888 [label="layer3.3.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290425888 -> 1607400747552
	1607400747552 [label=AccumulateGrad]
	1607400747312 -> 1607400747264
	1607290425968 [label="layer3.3.bn1.weight
 (256)" fillcolor=lightblue]
	1607290425968 -> 1607400747312
	1607400747312 [label=AccumulateGrad]
	1607400747168 -> 1607400747264
	1607290426048 [label="layer3.3.bn1.bias
 (256)" fillcolor=lightblue]
	1607290426048 -> 1607400747168
	1607400747168 [label=AccumulateGrad]
	1607400747072 -> 1607400746928
	1607290426608 [label="layer3.3.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290426608 -> 1607400747072
	1607400747072 [label=AccumulateGrad]
	1607400746880 -> 1607400746832
	1607290426368 [label="layer3.3.bn2.weight
 (256)" fillcolor=lightblue]
	1607290426368 -> 1607400746880
	1607400746880 [label=AccumulateGrad]
	1607400746736 -> 1607400746832
	1607290426528 [label="layer3.3.bn2.bias
 (256)" fillcolor=lightblue]
	1607290426528 -> 1607400746736
	1607400746736 [label=AccumulateGrad]
	1607400746640 -> 1607400746496
	1607290427088 [label="layer3.3.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290427088 -> 1607400746640
	1607400746640 [label=AccumulateGrad]
	1607400746448 -> 1607400746352
	1607290427168 [label="layer3.3.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290427168 -> 1607400746448
	1607400746448 [label=AccumulateGrad]
	1607400746400 -> 1607400746352
	1607290427248 [label="layer3.3.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290427248 -> 1607400746400
	1607400746400 [label=AccumulateGrad]
	1607400746304 -> 1607400746256
	1607400746160 -> 1607400745968
	1607290427728 [label="layer3.4.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290427728 -> 1607400746160
	1607400746160 [label=AccumulateGrad]
	1607400745920 -> 1607400745872
	1607290427808 [label="layer3.4.bn1.weight
 (256)" fillcolor=lightblue]
	1607290427808 -> 1607400745920
	1607400745920 [label=AccumulateGrad]
	1607400745776 -> 1607400745872
	1607290427888 [label="layer3.4.bn1.bias
 (256)" fillcolor=lightblue]
	1607290427888 -> 1607400745776
	1607400745776 [label=AccumulateGrad]
	1607400745680 -> 1607400735024
	1607290428448 [label="layer3.4.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290428448 -> 1607400745680
	1607400745680 [label=AccumulateGrad]
	1607400735168 -> 1607400735360
	1607290428368 [label="layer3.4.bn2.weight
 (256)" fillcolor=lightblue]
	1607290428368 -> 1607400735168
	1607400735168 [label=AccumulateGrad]
	1607400735648 -> 1607400735360
	1607290428528 [label="layer3.4.bn2.bias
 (256)" fillcolor=lightblue]
	1607290428528 -> 1607400735648
	1607400735648 [label=AccumulateGrad]
	1607400735888 -> 1607400736368
	1607290429008 [label="layer3.4.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290429008 -> 1607400735888
	1607400735888 [label=AccumulateGrad]
	1607400736416 -> 1607400736704
	1607290429088 [label="layer3.4.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290429088 -> 1607400736416
	1607400736416 [label=AccumulateGrad]
	1607400736560 -> 1607400736704
	1607290429168 [label="layer3.4.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290429168 -> 1607400736560
	1607400736560 [label=AccumulateGrad]
	1607400736896 -> 1607400736992
	1607400737280 -> 1607400737712
	1607290429648 [label="layer3.5.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290429648 -> 1607400737280
	1607400737280 [label=AccumulateGrad]
	1607400737856 -> 1607400738048
	1607290429728 [label="layer3.5.bn1.weight
 (256)" fillcolor=lightblue]
	1607290429728 -> 1607400737856
	1607400737856 [label=AccumulateGrad]
	1607400738288 -> 1607400738048
	1607290429808 [label="layer3.5.bn1.bias
 (256)" fillcolor=lightblue]
	1607290429808 -> 1607400738288
	1607400738288 [label=AccumulateGrad]
	1607400738480 -> 1607400738912
	1607290430368 [label="layer3.5.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290430368 -> 1607400738480
	1607400738480 [label=AccumulateGrad]
	1607400738960 -> 1607400739104
	1607290430288 [label="layer3.5.bn2.weight
 (256)" fillcolor=lightblue]
	1607290430288 -> 1607400738960
	1607400738960 [label=AccumulateGrad]
	1607400739392 -> 1607400739104
	1607290430448 [label="layer3.5.bn2.bias
 (256)" fillcolor=lightblue]
	1607290430448 -> 1607400739392
	1607400739392 [label=AccumulateGrad]
	1607400739536 -> 1607400740016
	1607290430928 [label="layer3.5.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290430928 -> 1607400739536
	1607400739536 [label=AccumulateGrad]
	1607400740160 -> 1607400740352
	1607290431008 [label="layer3.5.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290431008 -> 1607400740160
	1607400740160 [label=AccumulateGrad]
	1607400740208 -> 1607400740352
	1607290431088 [label="layer3.5.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290431088 -> 1607400740208
	1607400740208 [label=AccumulateGrad]
	1607400740496 -> 1607400740736
	1607400740880 -> 1607400741504
	1607290431488 [label="layer3.6.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290431488 -> 1607400740880
	1607400740880 [label=AccumulateGrad]
	1607400741456 -> 1607400741696
	1607290431568 [label="layer3.6.bn1.weight
 (256)" fillcolor=lightblue]
	1607290431568 -> 1607400741456
	1607400741456 [label=AccumulateGrad]
	1607400742032 -> 1607400741696
	1607290431648 [label="layer3.6.bn1.bias
 (256)" fillcolor=lightblue]
	1607290431648 -> 1607400742032
	1607400742032 [label=AccumulateGrad]
	1607400742224 -> 1607400742704
	1607290432208 [label="layer3.6.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290432208 -> 1607400742224
	1607400742224 [label=AccumulateGrad]
	1607400742848 -> 1607400742896
	1607290432128 [label="layer3.6.bn2.weight
 (256)" fillcolor=lightblue]
	1607290432128 -> 1607400742848
	1607400742848 [label=AccumulateGrad]
	1607400743232 -> 1607400742896
	1607290432288 [label="layer3.6.bn2.bias
 (256)" fillcolor=lightblue]
	1607290432288 -> 1607400743232
	1607400743232 [label=AccumulateGrad]
	1607400743472 -> 1607400743856
	1607290432768 [label="layer3.6.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290432768 -> 1607400743472
	1607400743472 [label=AccumulateGrad]
	1607400744000 -> 1607400744144
	1607290432848 [label="layer3.6.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290432848 -> 1607400744000
	1607400744000 [label=AccumulateGrad]
	1607400744192 -> 1607400744144
	1607290432928 [label="layer3.6.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290432928 -> 1607400744192
	1607400744192 [label=AccumulateGrad]
	1607400744384 -> 1607400744480
	1607400744768 -> 1607400745344
	1607290433408 [label="layer3.7.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290433408 -> 1607400744768
	1607400744768 [label=AccumulateGrad]
	1607400745488 -> 1607400745536
	1607290433488 [label="layer3.7.bn1.weight
 (256)" fillcolor=lightblue]
	1607290433488 -> 1607400745488
	1607400745488 [label=AccumulateGrad]
	1607400740544 -> 1607400745536
	1607290433568 [label="layer3.7.bn1.bias
 (256)" fillcolor=lightblue]
	1607290433568 -> 1607400740544
	1607400740544 [label=AccumulateGrad]
	1607400744048 -> 1607400745008
	1607290434128 [label="layer3.7.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290434128 -> 1607400744048
	1607400744048 [label=AccumulateGrad]
	1607400745200 -> 1607400739440
	1607290434048 [label="layer3.7.bn2.weight
 (256)" fillcolor=lightblue]
	1607290434048 -> 1607400745200
	1607400745200 [label=AccumulateGrad]
	1607400735792 -> 1607400739440
	1607290434208 [label="layer3.7.bn2.bias
 (256)" fillcolor=lightblue]
	1607290434208 -> 1607400735792
	1607400735792 [label=AccumulateGrad]
	1607400636480 -> 1607400636816
	1607290434688 [label="layer3.7.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290434688 -> 1607400636480
	1607400636480 [label=AccumulateGrad]
	1607400636960 -> 1607400637248
	1607290434768 [label="layer3.7.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290434768 -> 1607400636960
	1607400636960 [label=AccumulateGrad]
	1607400637104 -> 1607400637248
	1607290434848 [label="layer3.7.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290434848 -> 1607400637104
	1607400637104 [label=AccumulateGrad]
	1607400637296 -> 1607400637440
	1607400637728 -> 1607400638256
	1607290435328 [label="layer3.8.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290435328 -> 1607400637728
	1607400637728 [label=AccumulateGrad]
	1607400638400 -> 1607400638592
	1607290435408 [label="layer3.8.bn1.weight
 (256)" fillcolor=lightblue]
	1607290435408 -> 1607400638400
	1607400638400 [label=AccumulateGrad]
	1607400638784 -> 1607400638592
	1607290435488 [label="layer3.8.bn1.bias
 (256)" fillcolor=lightblue]
	1607290435488 -> 1607400638784
	1607400638784 [label=AccumulateGrad]
	1607400639024 -> 1607400639408
	1607290436048 [label="layer3.8.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290436048 -> 1607400639024
	1607400639024 [label=AccumulateGrad]
	1607400639552 -> 1607400639744
	1607290435968 [label="layer3.8.bn2.weight
 (256)" fillcolor=lightblue]
	1607290435968 -> 1607400639552
	1607400639552 [label=AccumulateGrad]
	1607400639888 -> 1607400639744
	1607290436128 [label="layer3.8.bn2.bias
 (256)" fillcolor=lightblue]
	1607290436128 -> 1607400639888
	1607400639888 [label=AccumulateGrad]
	1607400640176 -> 1607400640464
	1607290436608 [label="layer3.8.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290436608 -> 1607400640176
	1607400640176 [label=AccumulateGrad]
	1607400640704 -> 1607400640944
	1607290436688 [label="layer3.8.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290436688 -> 1607400640704
	1607400640704 [label=AccumulateGrad]
	1607400640800 -> 1607400640944
	1607290436768 [label="layer3.8.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290436768 -> 1607400640800
	1607400640800 [label=AccumulateGrad]
	1607400641088 -> 1607400641136
	1607400641472 -> 1607400641904
	1607290437248 [label="layer3.9.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290437248 -> 1607400641472
	1607400641472 [label=AccumulateGrad]
	1607400642048 -> 1607400642240
	1607290437328 [label="layer3.9.bn1.weight
 (256)" fillcolor=lightblue]
	1607290437328 -> 1607400642048
	1607400642048 [label=AccumulateGrad]
	1607400642480 -> 1607400642240
	1607290437408 [label="layer3.9.bn1.bias
 (256)" fillcolor=lightblue]
	1607290437408 -> 1607400642480
	1607400642480 [label=AccumulateGrad]
	1607400642720 -> 1607400643104
	1607290601872 [label="layer3.9.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290601872 -> 1607400642720
	1607400642720 [label=AccumulateGrad]
	1607400643248 -> 1607400637632
	1607290601792 [label="layer3.9.bn2.weight
 (256)" fillcolor=lightblue]
	1607290601792 -> 1607400643248
	1607400643248 [label=AccumulateGrad]
	1607400643632 -> 1607400637632
	1607290601952 [label="layer3.9.bn2.bias
 (256)" fillcolor=lightblue]
	1607290601952 -> 1607400643632
	1607400643632 [label=AccumulateGrad]
	1607400643824 -> 1607400644256
	1607290602432 [label="layer3.9.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290602432 -> 1607400643824
	1607400643824 [label=AccumulateGrad]
	1607400648048 -> 1607400648192
	1607290602512 [label="layer3.9.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290602512 -> 1607400648048
	1607400648048 [label=AccumulateGrad]
	1607400644304 -> 1607400648192
	1607290602592 [label="layer3.9.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290602592 -> 1607400644304
	1607400644304 [label=AccumulateGrad]
	1607400648960 -> 1607400648240
	1607400648624 -> 1607400649920
	1607290603072 [label="layer3.10.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290603072 -> 1607400648624
	1607400648624 [label=AccumulateGrad]
	1607400649056 -> 1607400649584
	1607290603152 [label="layer3.10.bn1.weight
 (256)" fillcolor=lightblue]
	1607290603152 -> 1607400649056
	1607400649056 [label=AccumulateGrad]
	1607400649536 -> 1607400649584
	1607290603232 [label="layer3.10.bn1.bias
 (256)" fillcolor=lightblue]
	1607290603232 -> 1607400649536
	1607400649536 [label=AccumulateGrad]
	1607400650688 -> 1607400650304
	1607290603792 [label="layer3.10.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290603792 -> 1607400650688
	1607400650688 [label=AccumulateGrad]
	1607400650112 -> 1607400651072
	1607290603712 [label="layer3.10.bn2.weight
 (256)" fillcolor=lightblue]
	1607290603712 -> 1607400650112
	1607400650112 [label=AccumulateGrad]
	1607400651264 -> 1607400651072
	1607290603872 [label="layer3.10.bn2.bias
 (256)" fillcolor=lightblue]
	1607290603872 -> 1607400651264
	1607400651264 [label=AccumulateGrad]
	1607400651504 -> 1607400651888
	1607290604352 [label="layer3.10.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290604352 -> 1607400651504
	1607400651504 [label=AccumulateGrad]
	1607400652032 -> 1607400640560
	1607290604432 [label="layer3.10.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290604432 -> 1607400652032
	1607400652032 [label=AccumulateGrad]
	1607400652224 -> 1607400640560
	1607290604512 [label="layer3.10.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290604512 -> 1607400652224
	1607400652224 [label=AccumulateGrad]
	1607400652416 -> 1607400652368
	1607400643536 -> 1607400643296
	1607290604992 [label="layer3.11.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290604992 -> 1607400643536
	1607400643536 [label=AccumulateGrad]
	1607400646608 -> 1607400645792
	1607290605072 [label="layer3.11.bn1.weight
 (256)" fillcolor=lightblue]
	1607290605072 -> 1607400646608
	1607400646608 [label=AccumulateGrad]
	1607400646992 -> 1607400645792
	1607290605152 [label="layer3.11.bn1.bias
 (256)" fillcolor=lightblue]
	1607290605152 -> 1607400646992
	1607400646992 [label=AccumulateGrad]
	1607400647760 -> 1607400649728
	1607290605712 [label="layer3.11.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290605712 -> 1607400647760
	1607400647760 [label=AccumulateGrad]
	1607400647712 -> 1607400647568
	1607290605632 [label="layer3.11.bn2.weight
 (256)" fillcolor=lightblue]
	1607290605632 -> 1607400647712
	1607400647712 [label=AccumulateGrad]
	1607400647904 -> 1607400647568
	1607290605792 [label="layer3.11.bn2.bias
 (256)" fillcolor=lightblue]
	1607290605792 -> 1607400647904
	1607400647904 [label=AccumulateGrad]
	1607400647232 -> 1607400646848
	1607290605952 [label="layer3.11.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290605952 -> 1607400647232
	1607400647232 [label=AccumulateGrad]
	1607400646704 -> 1607400646224
	1607290606272 [label="layer3.11.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290606272 -> 1607400646704
	1607400646704 [label=AccumulateGrad]
	1607400646560 -> 1607400646224
	1607290606352 [label="layer3.11.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290606352 -> 1607400646560
	1607400646560 [label=AccumulateGrad]
	1607400646368 -> 1607400646176
	1607400645888 -> 1607400645408
	1607290606832 [label="layer3.12.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290606832 -> 1607400645888
	1607400645888 [label=AccumulateGrad]
	1607400645216 -> 1607400645120
	1607290606912 [label="layer3.12.bn1.weight
 (256)" fillcolor=lightblue]
	1607290606912 -> 1607400645216
	1607400645216 [label=AccumulateGrad]
	1607400644928 -> 1607400645120
	1607290606992 [label="layer3.12.bn1.bias
 (256)" fillcolor=lightblue]
	1607290606992 -> 1607400644928
	1607400644928 [label=AccumulateGrad]
	1607400644592 -> 1607255141408
	1607290607552 [label="layer3.12.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290607552 -> 1607400644592
	1607400644592 [label=AccumulateGrad]
	1607400428768 -> 1607400427088
	1607290607472 [label="layer3.12.bn2.weight
 (256)" fillcolor=lightblue]
	1607290607472 -> 1607400428768
	1607400428768 [label=AccumulateGrad]
	1607400649248 -> 1607400427088
	1607290607632 [label="layer3.12.bn2.bias
 (256)" fillcolor=lightblue]
	1607290607632 -> 1607400649248
	1607400649248 [label=AccumulateGrad]
	1607400423824 -> 1607400439760
	1607290608112 [label="layer3.12.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290608112 -> 1607400423824
	1607400423824 [label=AccumulateGrad]
	1607400431600 -> 1607400431120
	1607290608192 [label="layer3.12.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290608192 -> 1607400431600
	1607400431600 [label=AccumulateGrad]
	1607400433376 -> 1607400431120
	1607290608272 [label="layer3.12.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290608272 -> 1607400433376
	1607400433376 [label=AccumulateGrad]
	1607400433712 -> 1607400431264
	1607400430880 -> 1607400434288
	1607290608752 [label="layer3.13.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290608752 -> 1607400430880
	1607400430880 [label=AccumulateGrad]
	1607400438992 -> 1607400430736
	1607290608832 [label="layer3.13.bn1.weight
 (256)" fillcolor=lightblue]
	1607290608832 -> 1607400438992
	1607400438992 [label=AccumulateGrad]
	1607400438704 -> 1607400430736
	1607290608912 [label="layer3.13.bn1.bias
 (256)" fillcolor=lightblue]
	1607290608912 -> 1607400438704
	1607400438704 [label=AccumulateGrad]
	1607400432560 -> 1607400430112
	1607290609472 [label="layer3.13.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290609472 -> 1607400432560
	1607400432560 [label=AccumulateGrad]
	1607400438416 -> 1607400423488
	1607290609392 [label="layer3.13.bn2.weight
 (256)" fillcolor=lightblue]
	1607290609392 -> 1607400438416
	1607400438416 [label=AccumulateGrad]
	1607400423872 -> 1607400423488
	1607290609552 [label="layer3.13.bn2.bias
 (256)" fillcolor=lightblue]
	1607290609552 -> 1607400423872
	1607400423872 [label=AccumulateGrad]
	1607400424160 -> 1607400424640
	1607290610032 [label="layer3.13.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290610032 -> 1607400424160
	1607400424160 [label=AccumulateGrad]
	1607400424736 -> 1607400425072
	1607290610112 [label="layer3.13.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290610112 -> 1607400424736
	1607400424736 [label=AccumulateGrad]
	1607400424880 -> 1607400425072
	1607290610192 [label="layer3.13.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290610192 -> 1607400424880
	1607400424880 [label=AccumulateGrad]
	1607400425216 -> 1607400425456
	1607400425696 -> 1607400426320
	1607290610672 [label="layer3.14.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290610672 -> 1607400425696
	1607400425696 [label=AccumulateGrad]
	1607400426416 -> 1607400426464
	1607290610752 [label="layer3.14.bn1.weight
 (256)" fillcolor=lightblue]
	1607290610752 -> 1607400426416
	1607400426416 [label=AccumulateGrad]
	1607400426704 -> 1607400426464
	1607290610832 [label="layer3.14.bn1.bias
 (256)" fillcolor=lightblue]
	1607290610832 -> 1607400426704
	1607400426704 [label=AccumulateGrad]
	1607400427040 -> 1607400427424
	1607290611392 [label="layer3.14.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290611392 -> 1607400427040
	1607400427040 [label=AccumulateGrad]
	1607400427568 -> 1607400427712
	1607290611312 [label="layer3.14.bn2.weight
 (256)" fillcolor=lightblue]
	1607290611312 -> 1607400427568
	1607400427568 [label=AccumulateGrad]
	1607400428096 -> 1607400427712
	1607290611472 [label="layer3.14.bn2.bias
 (256)" fillcolor=lightblue]
	1607290611472 -> 1607400428096
	1607400428096 [label=AccumulateGrad]
	1607400428384 -> 1607400428912
	1607290611952 [label="layer3.14.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290611952 -> 1607400428384
	1607400428384 [label=AccumulateGrad]
	1607400428960 -> 1607400429296
	1607290612032 [label="layer3.14.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290612032 -> 1607400428960
	1607400428960 [label=AccumulateGrad]
	1607400429104 -> 1607400429296
	1607290612112 [label="layer3.14.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290612112 -> 1607400429104
	1607400429104 [label=AccumulateGrad]
	1607400429488 -> 1607400429680
	1607400429632 -> 1607400430208
	1607290612592 [label="layer3.15.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290612592 -> 1607400429632
	1607400429632 [label=AccumulateGrad]
	1607400430256 -> 1607400430400
	1607290612672 [label="layer3.15.bn1.weight
 (256)" fillcolor=lightblue]
	1607290612672 -> 1607400430256
	1607400430256 [label=AccumulateGrad]
	1607400430688 -> 1607400430400
	1607290612752 [label="layer3.15.bn1.bias
 (256)" fillcolor=lightblue]
	1607290612752 -> 1607400430688
	1607400430688 [label=AccumulateGrad]
	1607400430976 -> 1607400431360
	1607290613312 [label="layer3.15.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290613312 -> 1607400430976
	1607400430976 [label=AccumulateGrad]
	1607400431552 -> 1607400431648
	1607290613232 [label="layer3.15.bn2.weight
 (256)" fillcolor=lightblue]
	1607290613232 -> 1607400431552
	1607400431552 [label=AccumulateGrad]
	1607400431984 -> 1607400431648
	1607290613392 [label="layer3.15.bn2.bias
 (256)" fillcolor=lightblue]
	1607290613392 -> 1607400431984
	1607400431984 [label=AccumulateGrad]
	1607400432272 -> 1607400438128
	1607290613872 [label="layer3.15.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290613872 -> 1607400432272
	1607400432272 [label=AccumulateGrad]
	1607400432512 -> 1607400432896
	1607290613952 [label="layer3.15.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290613952 -> 1607400432512
	1607400432512 [label=AccumulateGrad]
	1607400432704 -> 1607400432896
	1607290614032 [label="layer3.15.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290614032 -> 1607400432704
	1607400432704 [label=AccumulateGrad]
	1607400432848 -> 1607400433088
	1607400433328 -> 1607400433856
	1607290614512 [label="layer3.16.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290614512 -> 1607400433328
	1607400433328 [label=AccumulateGrad]
	1607400433952 -> 1607400434144
	1607290614592 [label="layer3.16.bn1.weight
 (256)" fillcolor=lightblue]
	1607290614592 -> 1607400433952
	1607400433952 [label=AccumulateGrad]
	1607400434240 -> 1607400434144
	1607290614672 [label="layer3.16.bn1.bias
 (256)" fillcolor=lightblue]
	1607290614672 -> 1607400434240
	1607400434240 [label=AccumulateGrad]
	1607400434624 -> 1607400434912
	1607290615232 [label="layer3.16.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290615232 -> 1607400434624
	1607400434624 [label=AccumulateGrad]
	1607400435056 -> 1607400435248
	1607290615152 [label="layer3.16.bn2.weight
 (256)" fillcolor=lightblue]
	1607290615152 -> 1607400435056
	1607400435056 [label=AccumulateGrad]
	1607400435440 -> 1607400435248
	1607290615312 [label="layer3.16.bn2.bias
 (256)" fillcolor=lightblue]
	1607290615312 -> 1607400435440
	1607400435440 [label=AccumulateGrad]
	1607400435728 -> 1607400436112
	1607290615792 [label="layer3.16.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290615792 -> 1607400435728
	1607400435728 [label=AccumulateGrad]
	1607400436256 -> 1607400436592
	1607290615872 [label="layer3.16.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290615872 -> 1607400436256
	1607400436256 [label=AccumulateGrad]
	1607400436400 -> 1607400436592
	1607290615952 [label="layer3.16.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290615952 -> 1607400436400
	1607400436400 [label=AccumulateGrad]
	1607400436736 -> 1607400437792
	1607400437024 -> 1607400437552
	1607290616432 [label="layer3.17.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290616432 -> 1607400437024
	1607400437024 [label=AccumulateGrad]
	1607400437600 -> 1607400437744
	1607290616512 [label="layer3.17.bn1.weight
 (256)" fillcolor=lightblue]
	1607290616512 -> 1607400437600
	1607400437600 [label=AccumulateGrad]
	1607400437936 -> 1607400437744
	1607290616592 [label="layer3.17.bn1.bias
 (256)" fillcolor=lightblue]
	1607290616592 -> 1607400437936
	1607400437936 [label=AccumulateGrad]
	1607400438272 -> 1607400438656
	1607290617152 [label="layer3.17.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290617152 -> 1607400438272
	1607400438272 [label=AccumulateGrad]
	1607400438848 -> 1607400438944
	1607290617072 [label="layer3.17.bn2.weight
 (256)" fillcolor=lightblue]
	1607290617072 -> 1607400438848
	1607400438848 [label=AccumulateGrad]
	1607400439232 -> 1607400438944
	1607290617232 [label="layer3.17.bn2.bias
 (256)" fillcolor=lightblue]
	1607290617232 -> 1607400439232
	1607400439232 [label=AccumulateGrad]
	1607400439424 -> 1607400424208
	1607290617712 [label="layer3.17.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290617712 -> 1607400439424
	1607400439424 [label=AccumulateGrad]
	1607400439472 -> 1607400429344
	1607290617792 [label="layer3.17.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290617792 -> 1607400439472
	1607400439472 [label=AccumulateGrad]
	1607400423920 -> 1607400429344
	1607290798160 [label="layer3.17.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290798160 -> 1607400423920
	1607400423920 [label=AccumulateGrad]
	1607400437216 -> 1607400435104
	1607400429152 -> 1607400429536
	1607290798640 [label="layer3.18.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290798640 -> 1607400429152
	1607400429152 [label=AccumulateGrad]
	1607400431888 -> 1607400329072
	1607290798720 [label="layer3.18.bn1.weight
 (256)" fillcolor=lightblue]
	1607290798720 -> 1607400431888
	1607400431888 [label=AccumulateGrad]
	1607400435632 -> 1607400329072
	1607290798800 [label="layer3.18.bn1.bias
 (256)" fillcolor=lightblue]
	1607290798800 -> 1607400435632
	1607400435632 [label=AccumulateGrad]
	1607400325760 -> 1607400325232
	1607290799360 [label="layer3.18.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290799360 -> 1607400325760
	1607400325760 [label=AccumulateGrad]
	1607400333152 -> 1607400333200
	1607290799280 [label="layer3.18.bn2.weight
 (256)" fillcolor=lightblue]
	1607290799280 -> 1607400333152
	1607400333152 [label=AccumulateGrad]
	1607400341216 -> 1607400333200
	1607290799440 [label="layer3.18.bn2.bias
 (256)" fillcolor=lightblue]
	1607290799440 -> 1607400341216
	1607400341216 [label=AccumulateGrad]
	1607400340880 -> 1607400332768
	1607290799920 [label="layer3.18.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290799920 -> 1607400340880
	1607400340880 [label=AccumulateGrad]
	1607400340640 -> 1607400332336
	1607290800000 [label="layer3.18.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290800000 -> 1607400340640
	1607400340640 [label=AccumulateGrad]
	1607400334544 -> 1607400332336
	1607290800080 [label="layer3.18.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290800080 -> 1607400334544
	1607400334544 [label=AccumulateGrad]
	1607400334496 -> 1607400325328
	1607400325712 -> 1607400326336
	1607290800560 [label="layer3.19.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290800560 -> 1607400325712
	1607400325712 [label=AccumulateGrad]
	1607400326528 -> 1607400340496
	1607290800480 [label="layer3.19.bn1.weight
 (256)" fillcolor=lightblue]
	1607290800480 -> 1607400326528
	1607400326528 [label=AccumulateGrad]
	1607400326864 -> 1607400340496
	1607290800640 [label="layer3.19.bn1.bias
 (256)" fillcolor=lightblue]
	1607290800640 -> 1607400326864
	1607400326864 [label=AccumulateGrad]
	1607400327104 -> 1607400327680
	1607290801200 [label="layer3.19.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290801200 -> 1607400327104
	1607400327104 [label=AccumulateGrad]
	1607400327776 -> 1607400327920
	1607290801120 [label="layer3.19.bn2.weight
 (256)" fillcolor=lightblue]
	1607290801120 -> 1607400327776
	1607400327776 [label=AccumulateGrad]
	1607400328064 -> 1607400327920
	1607290801280 [label="layer3.19.bn2.bias
 (256)" fillcolor=lightblue]
	1607290801280 -> 1607400328064
	1607400328064 [label=AccumulateGrad]
	1607400328256 -> 1607400328832
	1607290801760 [label="layer3.19.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290801760 -> 1607400328256
	1607400328256 [label=AccumulateGrad]
	1607400328976 -> 1607400329168
	1607290801840 [label="layer3.19.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290801840 -> 1607400328976
	1607400328976 [label=AccumulateGrad]
	1607400332528 -> 1607400329168
	1607290801920 [label="layer3.19.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290801920 -> 1607400332528
	1607400332528 [label=AccumulateGrad]
	1607400329408 -> 1607400329552
	1607400329648 -> 1607400329936
	1607290802400 [label="layer3.20.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290802400 -> 1607400329648
	1607400329648 [label=AccumulateGrad]
	1607400330176 -> 1607400330368
	1607290802480 [label="layer3.20.bn1.weight
 (256)" fillcolor=lightblue]
	1607290802480 -> 1607400330176
	1607400330176 [label=AccumulateGrad]
	1607400330560 -> 1607400330368
	1607290802560 [label="layer3.20.bn1.bias
 (256)" fillcolor=lightblue]
	1607290802560 -> 1607400330560
	1607400330560 [label=AccumulateGrad]
	1607400330992 -> 1607400331520
	1607290803120 [label="layer3.20.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290803120 -> 1607400330992
	1607400330992 [label=AccumulateGrad]
	1607400331616 -> 1607400331760
	1607290803040 [label="layer3.20.bn2.weight
 (256)" fillcolor=lightblue]
	1607290803040 -> 1607400331616
	1607400331616 [label=AccumulateGrad]
	1607400331904 -> 1607400331760
	1607290803200 [label="layer3.20.bn2.bias
 (256)" fillcolor=lightblue]
	1607290803200 -> 1607400331904
	1607400331904 [label=AccumulateGrad]
	1607400332096 -> 1607400332672
	1607290803680 [label="layer3.20.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290803680 -> 1607400332096
	1607400332096 [label=AccumulateGrad]
	1607400332864 -> 1607400333248
	1607290803600 [label="layer3.20.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290803600 -> 1607400332864
	1607400332864 [label=AccumulateGrad]
	1607400333056 -> 1607400333248
	1607290803760 [label="layer3.20.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290803760 -> 1607400333056
	1607400333056 [label=AccumulateGrad]
	1607400333440 -> 1607400333632
	1607400333968 -> 1607400334736
	1607290804160 [label="layer3.21.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290804160 -> 1607400333968
	1607400333968 [label=AccumulateGrad]
	1607400334928 -> 1607400335168
	1607290804320 [label="layer3.21.bn1.weight
 (256)" fillcolor=lightblue]
	1607290804320 -> 1607400334928
	1607400334928 [label=AccumulateGrad]
	1607400335264 -> 1607400335168
	1607290804400 [label="layer3.21.bn1.bias
 (256)" fillcolor=lightblue]
	1607290804400 -> 1607400335264
	1607400335264 [label=AccumulateGrad]
	1607400335552 -> 1607400335936
	1607290804960 [label="layer3.21.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290804960 -> 1607400335552
	1607400335552 [label=AccumulateGrad]
	1607400336080 -> 1607400336128
	1607290804880 [label="layer3.21.bn2.weight
 (256)" fillcolor=lightblue]
	1607290804880 -> 1607400336080
	1607400336080 [label=AccumulateGrad]
	1607400336560 -> 1607400336128
	1607290805040 [label="layer3.21.bn2.bias
 (256)" fillcolor=lightblue]
	1607290805040 -> 1607400336560
	1607400336560 [label=AccumulateGrad]
	1607400336704 -> 1607400337280
	1607290805520 [label="layer3.21.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290805520 -> 1607400336704
	1607400336704 [label=AccumulateGrad]
	1607400337376 -> 1607400337664
	1607290805600 [label="layer3.21.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290805600 -> 1607400337376
	1607400337376 [label=AccumulateGrad]
	1607400337568 -> 1607400337664
	1607290805680 [label="layer3.21.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290805680 -> 1607400337568
	1607400337568 [label=AccumulateGrad]
	1607400336512 -> 1607400337856
	1607400338048 -> 1607400338624
	1607290806160 [label="layer3.22.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290806160 -> 1607400338048
	1607400338048 [label=AccumulateGrad]
	1607400338768 -> 1607400338960
	1607290806240 [label="layer3.22.bn1.weight
 (256)" fillcolor=lightblue]
	1607290806240 -> 1607400338768
	1607400338768 [label=AccumulateGrad]
	1607400334064 -> 1607400338960
	1607290806320 [label="layer3.22.bn1.bias
 (256)" fillcolor=lightblue]
	1607290806320 -> 1607400334064
	1607400334064 [label=AccumulateGrad]
	1607400339584 -> 1607400339968
	1607290806880 [label="layer3.22.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290806880 -> 1607400339584
	1607400339584 [label=AccumulateGrad]
	1607400340160 -> 1607400340352
	1607290806800 [label="layer3.22.bn2.weight
 (256)" fillcolor=lightblue]
	1607290806800 -> 1607400340160
	1607400340160 [label=AccumulateGrad]
	1607400340736 -> 1607400340352
	1607290806960 [label="layer3.22.bn2.bias
 (256)" fillcolor=lightblue]
	1607290806960 -> 1607400340736
	1607400340736 [label=AccumulateGrad]
	1607400341072 -> 1607400341456
	1607290807120 [label="layer3.22.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290807120 -> 1607400341072
	1607400341072 [label=AccumulateGrad]
	1607400335456 -> 1607400337712
	1607290807440 [label="layer3.22.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290807440 -> 1607400335456
	1607400335456 [label=AccumulateGrad]
	1607400338192 -> 1607400337712
	1607290807520 [label="layer3.22.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290807520 -> 1607400338192
	1607400338192 [label=AccumulateGrad]
	1607400340208 -> 1607400328112
	1607400336464 -> 1607400334112
	1607290808000 [label="layer3.23.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290808000 -> 1607400336464
	1607400336464 [label=AccumulateGrad]
	1607400338864 -> 1607400339056
	1607290808080 [label="layer3.23.bn1.weight
 (256)" fillcolor=lightblue]
	1607290808080 -> 1607400338864
	1607400338864 [label=AccumulateGrad]
	1607400330944 -> 1607400339056
	1607290808160 [label="layer3.23.bn1.bias
 (256)" fillcolor=lightblue]
	1607290808160 -> 1607400330944
	1607400330944 [label=AccumulateGrad]
	1607400331952 -> 1607400339104
	1607290808720 [label="layer3.23.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290808720 -> 1607400331952
	1607400331952 [label=AccumulateGrad]
	1607400339296 -> 1607400339248
	1607290808640 [label="layer3.23.bn2.weight
 (256)" fillcolor=lightblue]
	1607290808640 -> 1607400339296
	1607400339296 [label=AccumulateGrad]
	1607400337232 -> 1607400339248
	1607290808800 [label="layer3.23.bn2.bias
 (256)" fillcolor=lightblue]
	1607290808800 -> 1607400337232
	1607400337232 [label=AccumulateGrad]
	1607400339536 -> 1607286903648
	1607290809280 [label="layer3.23.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290809280 -> 1607400339536
	1607400339536 [label=AccumulateGrad]
	1607400148128 -> 1607400149088
	1607290809360 [label="layer3.23.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290809360 -> 1607400148128
	1607400148128 [label=AccumulateGrad]
	1607400146592 -> 1607400149088
	1607290809440 [label="layer3.23.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290809440 -> 1607400146592
	1607400146592 [label=AccumulateGrad]
	1607400149856 -> 1607400145104
	1607400145440 -> 1607400146352
	1607290809920 [label="layer3.24.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290809920 -> 1607400145440
	1607400145440 [label=AccumulateGrad]
	1607400149664 -> 1607400146400
	1607290810000 [label="layer3.24.bn1.weight
 (256)" fillcolor=lightblue]
	1607290810000 -> 1607400149664
	1607400149664 [label=AccumulateGrad]
	1607400146928 -> 1607400146400
	1607290810080 [label="layer3.24.bn1.bias
 (256)" fillcolor=lightblue]
	1607290810080 -> 1607400146928
	1607400146928 [label=AccumulateGrad]
	1607400147360 -> 1607400147936
	1607290810640 [label="layer3.24.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290810640 -> 1607400147360
	1607400147360 [label=AccumulateGrad]
	1607400148176 -> 1607400148416
	1607290810560 [label="layer3.24.bn2.weight
 (256)" fillcolor=lightblue]
	1607290810560 -> 1607400148176
	1607400148176 [label=AccumulateGrad]
	1607400148656 -> 1607400148416
	1607290810720 [label="layer3.24.bn2.bias
 (256)" fillcolor=lightblue]
	1607290810720 -> 1607400148656
	1607400148656 [label=AccumulateGrad]
	1607400149136 -> 1607400149712
	1607290811200 [label="layer3.24.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290811200 -> 1607400149136
	1607400149136 [label=AccumulateGrad]
	1607400149952 -> 1607400150432
	1607290811280 [label="layer3.24.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290811280 -> 1607400149952
	1607400149952 [label=AccumulateGrad]
	1607400150192 -> 1607400150432
	1607290811360 [label="layer3.24.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290811360 -> 1607400150192
	1607400150192 [label=AccumulateGrad]
	1607400150528 -> 1607400150720
	1607400151152 -> 1607400151872
	1607290811840 [label="layer3.25.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290811840 -> 1607400151152
	1607400151152 [label=AccumulateGrad]
	1607400152016 -> 1607400152208
	1607290811920 [label="layer3.25.bn1.weight
 (256)" fillcolor=lightblue]
	1607290811920 -> 1607400152016
	1607400152016 [label=AccumulateGrad]
	1607400152592 -> 1607400152208
	1607290812000 [label="layer3.25.bn1.bias
 (256)" fillcolor=lightblue]
	1607290812000 -> 1607400152592
	1607400152592 [label=AccumulateGrad]
	1607400153024 -> 1607400153648
	1607290812560 [label="layer3.25.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290812560 -> 1607400153024
	1607400153024 [label=AccumulateGrad]
	1607400153888 -> 1607400154128
	1607290812480 [label="layer3.25.bn2.weight
 (256)" fillcolor=lightblue]
	1607290812480 -> 1607400153888
	1607400153888 [label=AccumulateGrad]
	1607400154512 -> 1607400154128
	1607290812640 [label="layer3.25.bn2.bias
 (256)" fillcolor=lightblue]
	1607290812640 -> 1607400154512
	1607400154512 [label=AccumulateGrad]
	1607400154944 -> 1607400155520
	1607290813120 [label="layer3.25.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290813120 -> 1607400154944
	1607400154944 [label=AccumulateGrad]
	1607400155712 -> 1607400155904
	1607290813200 [label="layer3.25.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290813200 -> 1607400155712
	1607400155712 [label=AccumulateGrad]
	1607400156624 -> 1607400155904
	1607290813280 [label="layer3.25.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290813280 -> 1607400156624
	1607400156624 [label=AccumulateGrad]
	1607400156144 -> 1607400156288
	1607400156672 -> 1607400157344
	1607290813760 [label="layer3.26.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290813760 -> 1607400156672
	1607400156672 [label=AccumulateGrad]
	1607400157440 -> 1607400157632
	1607290813840 [label="layer3.26.bn1.weight
 (256)" fillcolor=lightblue]
	1607290813840 -> 1607400157440
	1607400157440 [label=AccumulateGrad]
	1607400158016 -> 1607400157632
	1607290813920 [label="layer3.26.bn1.bias
 (256)" fillcolor=lightblue]
	1607290813920 -> 1607400158016
	1607400158016 [label=AccumulateGrad]
	1607400158352 -> 1607400158688
	1607290962000 [label="layer3.26.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290962000 -> 1607400158352
	1607400158352 [label=AccumulateGrad]
	1607400158784 -> 1607400158976
	1607290814400 [label="layer3.26.bn2.weight
 (256)" fillcolor=lightblue]
	1607290814400 -> 1607400158784
	1607400158784 [label=AccumulateGrad]
	1607400159168 -> 1607400158976
	1607290962080 [label="layer3.26.bn2.bias
 (256)" fillcolor=lightblue]
	1607290962080 -> 1607400159168
	1607400159168 [label=AccumulateGrad]
	1607400159360 -> 1607400159744
	1607290962560 [label="layer3.26.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290962560 -> 1607400159360
	1607400159360 [label=AccumulateGrad]
	1607400159936 -> 1607400160176
	1607290962640 [label="layer3.26.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290962640 -> 1607400159936
	1607400159936 [label=AccumulateGrad]
	1607400160032 -> 1607400160176
	1607290962720 [label="layer3.26.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290962720 -> 1607400160032
	1607400160032 [label=AccumulateGrad]
	1607400160416 -> 1607400160512
	1607400157488 -> 1607400145824
	1607290963200 [label="layer3.27.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290963200 -> 1607400157488
	1607400157488 [label=AccumulateGrad]
	1607400158160 -> 1607400157104
	1607290963280 [label="layer3.27.bn1.weight
 (256)" fillcolor=lightblue]
	1607290963280 -> 1607400158160
	1607400158160 [label=AccumulateGrad]
	1607400145584 -> 1607400157104
	1607290963360 [label="layer3.27.bn1.bias
 (256)" fillcolor=lightblue]
	1607290963360 -> 1607400145584
	1607400145584 [label=AccumulateGrad]
	1607400155040 -> 1607400155808
	1607290963920 [label="layer3.27.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290963920 -> 1607400155040
	1607400155040 [label=AccumulateGrad]
	1607400156048 -> 1607400155280
	1607290963840 [label="layer3.27.bn2.weight
 (256)" fillcolor=lightblue]
	1607290963840 -> 1607400156048
	1607400156048 [label=AccumulateGrad]
	1607400156816 -> 1607400155280
	1607290964000 [label="layer3.27.bn2.bias
 (256)" fillcolor=lightblue]
	1607290964000 -> 1607400156816
	1607400156816 [label=AccumulateGrad]
	1607400248016 -> 1607400243504
	1607290964480 [label="layer3.27.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290964480 -> 1607400248016
	1607400248016 [label=AccumulateGrad]
	1607400243696 -> 1607400244080
	1607290964560 [label="layer3.27.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290964560 -> 1607400243696
	1607400243696 [label=AccumulateGrad]
	1607400243888 -> 1607400244080
	1607290964640 [label="layer3.27.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290964640 -> 1607400243888
	1607400243888 [label=AccumulateGrad]
	1607400244128 -> 1607400244320
	1607400244752 -> 1607400245376
	1607290965120 [label="layer3.28.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290965120 -> 1607400244752
	1607400244752 [label=AccumulateGrad]
	1607400245568 -> 1607400245712
	1607290965200 [label="layer3.28.bn1.weight
 (256)" fillcolor=lightblue]
	1607290965200 -> 1607400245568
	1607400245568 [label=AccumulateGrad]
	1607400245904 -> 1607400245712
	1607290965280 [label="layer3.28.bn1.bias
 (256)" fillcolor=lightblue]
	1607290965280 -> 1607400245904
	1607400245904 [label=AccumulateGrad]
	1607400246288 -> 1607400246672
	1607290965840 [label="layer3.28.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290965840 -> 1607400246288
	1607400246288 [label=AccumulateGrad]
	1607400246864 -> 1607400247104
	1607290965760 [label="layer3.28.bn2.weight
 (256)" fillcolor=lightblue]
	1607290965760 -> 1607400246864
	1607400246864 [label=AccumulateGrad]
	1607400247440 -> 1607400247104
	1607290965920 [label="layer3.28.bn2.bias
 (256)" fillcolor=lightblue]
	1607290965920 -> 1607400247440
	1607400247440 [label=AccumulateGrad]
	1607400247872 -> 1607400248400
	1607290966400 [label="layer3.28.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290966400 -> 1607400247872
	1607400247872 [label=AccumulateGrad]
	1607400248592 -> 1607400249072
	1607290966480 [label="layer3.28.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290966480 -> 1607400248592
	1607400248592 [label=AccumulateGrad]
	1607400248832 -> 1607400249072
	1607290966560 [label="layer3.28.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290966560 -> 1607400248832
	1607400248832 [label=AccumulateGrad]
	1607400249216 -> 1607400249312
	1607400249648 -> 1607400250080
	1607290967040 [label="layer3.29.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290967040 -> 1607400249648
	1607400249648 [label=AccumulateGrad]
	1607400250320 -> 1607400250464
	1607290967120 [label="layer3.29.bn1.weight
 (256)" fillcolor=lightblue]
	1607290967120 -> 1607400250320
	1607400250320 [label=AccumulateGrad]
	1607400250704 -> 1607400250464
	1607290967200 [label="layer3.29.bn1.bias
 (256)" fillcolor=lightblue]
	1607290967200 -> 1607400250704
	1607400250704 [label=AccumulateGrad]
	1607400251040 -> 1607400251616
	1607290967680 [label="layer3.29.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290967680 -> 1607400251040
	1607400251040 [label=AccumulateGrad]
	1607400251712 -> 1607400252000
	1607290967600 [label="layer3.29.bn2.weight
 (256)" fillcolor=lightblue]
	1607290967600 -> 1607400251712
	1607400251712 [label=AccumulateGrad]
	1607400252336 -> 1607400252000
	1607290967760 [label="layer3.29.bn2.bias
 (256)" fillcolor=lightblue]
	1607290967760 -> 1607400252336
	1607400252336 [label=AccumulateGrad]
	1607400252624 -> 1607400253056
	1607290968240 [label="layer3.29.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290968240 -> 1607400252624
	1607400252624 [label=AccumulateGrad]
	1607400253152 -> 1607400253488
	1607290968320 [label="layer3.29.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290968320 -> 1607400253152
	1607400253152 [label=AccumulateGrad]
	1607400253248 -> 1607400253488
	1607290968400 [label="layer3.29.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290968400 -> 1607400253248
	1607400253248 [label=AccumulateGrad]
	1607400253632 -> 1607400253776
	1607400254016 -> 1607400254640
	1607290968880 [label="layer3.30.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290968880 -> 1607400254016
	1607400254016 [label=AccumulateGrad]
	1607400254784 -> 1607400254928
	1607290968960 [label="layer3.30.bn1.weight
 (256)" fillcolor=lightblue]
	1607290968960 -> 1607400254784
	1607400254784 [label=AccumulateGrad]
	1607400255264 -> 1607400254928
	1607290969040 [label="layer3.30.bn1.bias
 (256)" fillcolor=lightblue]
	1607290969040 -> 1607400255264
	1607400255264 [label=AccumulateGrad]
	1607400255600 -> 1607400256080
	1607290969600 [label="layer3.30.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290969600 -> 1607400255600
	1607400255600 [label=AccumulateGrad]
	1607400256176 -> 1607400256368
	1607290969520 [label="layer3.30.bn2.weight
 (256)" fillcolor=lightblue]
	1607290969520 -> 1607400256176
	1607400256176 [label=AccumulateGrad]
	1607400256752 -> 1607400256368
	1607290969680 [label="layer3.30.bn2.bias
 (256)" fillcolor=lightblue]
	1607290969680 -> 1607400256752
	1607400256752 [label=AccumulateGrad]
	1607400257088 -> 1607400257568
	1607290970160 [label="layer3.30.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290970160 -> 1607400257088
	1607400257088 [label=AccumulateGrad]
	1607400257760 -> 1607400258000
	1607290970240 [label="layer3.30.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290970240 -> 1607400257760
	1607400257760 [label=AccumulateGrad]
	1607400255792 -> 1607400258000
	1607290970320 [label="layer3.30.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290970320 -> 1607400255792
	1607400255792 [label=AccumulateGrad]
	1607400258240 -> 1607400258432
	1607400258720 -> 1607400259344
	1607290970800 [label="layer3.31.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290970800 -> 1607400258720
	1607400258720 [label=AccumulateGrad]
	1607400259392 -> 1607400259536
	1607290970880 [label="layer3.31.bn1.weight
 (256)" fillcolor=lightblue]
	1607290970880 -> 1607400259392
	1607400259392 [label=AccumulateGrad]
	1607400244224 -> 1607400259536
	1607290970960 [label="layer3.31.bn1.bias
 (256)" fillcolor=lightblue]
	1607290970960 -> 1607400244224
	1607400244224 [label=AccumulateGrad]
	1607400258672 -> 1607400252432
	1607290971520 [label="layer3.31.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290971520 -> 1607400258672
	1607400258672 [label=AccumulateGrad]
	1607400252912 -> 1607400254448
	1607290971440 [label="layer3.31.bn2.weight
 (256)" fillcolor=lightblue]
	1607290971440 -> 1607400252912
	1607400252912 [label=AccumulateGrad]
	1607400255984 -> 1607400254448
	1607290971600 [label="layer3.31.bn2.bias
 (256)" fillcolor=lightblue]
	1607290971600 -> 1607400255984
	1607400255984 [label=AccumulateGrad]
	1607400543216 -> 1607400549408
	1607290972080 [label="layer3.31.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290972080 -> 1607400543216
	1607400543216 [label=AccumulateGrad]
	1607400550368 -> 1607400549936
	1607290972160 [label="layer3.31.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290972160 -> 1607400550368
	1607400550368 [label=AccumulateGrad]
	1607400550224 -> 1607400549936
	1607290972240 [label="layer3.31.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290972240 -> 1607400550224
	1607400550224 [label=AccumulateGrad]
	1607400548784 -> 1607400548640
	1607400549072 -> 1607400538608
	1607290972720 [label="layer3.32.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290972720 -> 1607400549072
	1607400549072 [label=AccumulateGrad]
	1607400538800 -> 1607400538944
	1607290972800 [label="layer3.32.bn1.weight
 (256)" fillcolor=lightblue]
	1607290972800 -> 1607400538800
	1607400538800 [label=AccumulateGrad]
	1607400539136 -> 1607400538944
	1607290972880 [label="layer3.32.bn1.bias
 (256)" fillcolor=lightblue]
	1607290972880 -> 1607400539136
	1607400539136 [label=AccumulateGrad]
	1607400539520 -> 1607400539808
	1607290973440 [label="layer3.32.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290973440 -> 1607400539520
	1607400539520 [label=AccumulateGrad]
	1607400539952 -> 1607400540096
	1607290973360 [label="layer3.32.bn2.weight
 (256)" fillcolor=lightblue]
	1607290973360 -> 1607400539952
	1607400539952 [label=AccumulateGrad]
	1607400540336 -> 1607400540096
	1607290973520 [label="layer3.32.bn2.bias
 (256)" fillcolor=lightblue]
	1607290973520 -> 1607400540336
	1607400540336 [label=AccumulateGrad]
	1607400540672 -> 1607400540960
	1607290974000 [label="layer3.32.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290974000 -> 1607400540672
	1607400540672 [label=AccumulateGrad]
	1607400541104 -> 1607400541440
	1607290974080 [label="layer3.32.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290974080 -> 1607400541104
	1607400541104 [label=AccumulateGrad]
	1607400541248 -> 1607400541440
	1607290974160 [label="layer3.32.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290974160 -> 1607400541248
	1607400541248 [label=AccumulateGrad]
	1607400541536 -> 1607400541584
	1607400541872 -> 1607400542400
	1607290974640 [label="layer3.33.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290974640 -> 1607400541872
	1607400541872 [label=AccumulateGrad]
	1607400542496 -> 1607400542640
	1607290974720 [label="layer3.33.bn1.weight
 (256)" fillcolor=lightblue]
	1607290974720 -> 1607400542496
	1607400542496 [label=AccumulateGrad]
	1607400542832 -> 1607400542640
	1607290974800 [label="layer3.33.bn1.bias
 (256)" fillcolor=lightblue]
	1607290974800 -> 1607400542832
	1607400542832 [label=AccumulateGrad]
	1607400543168 -> 1607400543552
	1607290975360 [label="layer3.33.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290975360 -> 1607400543168
	1607400543168 [label=AccumulateGrad]
	1607400543744 -> 1607400543840
	1607290975280 [label="layer3.33.bn2.weight
 (256)" fillcolor=lightblue]
	1607290975280 -> 1607400543744
	1607400543744 [label=AccumulateGrad]
	1607400544176 -> 1607400543840
	1607290975440 [label="layer3.33.bn2.bias
 (256)" fillcolor=lightblue]
	1607290975440 -> 1607400544176
	1607400544176 [label=AccumulateGrad]
	1607400544416 -> 1607400544944
	1607290975920 [label="layer3.33.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290975920 -> 1607400544416
	1607400544416 [label=AccumulateGrad]
	1607400545088 -> 1607400545328
	1607290976000 [label="layer3.33.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290976000 -> 1607400545088
	1607400545088 [label=AccumulateGrad]
	1607400545184 -> 1607400545328
	1607290976080 [label="layer3.33.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290976080 -> 1607400545184
	1607400545184 [label=AccumulateGrad]
	1607400545472 -> 1607400545664
	1607400545856 -> 1607400546288
	1607290976560 [label="layer3.34.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607290976560 -> 1607400545856
	1607400545856 [label=AccumulateGrad]
	1607400546432 -> 1607400546624
	1607290976640 [label="layer3.34.bn1.weight
 (256)" fillcolor=lightblue]
	1607290976640 -> 1607400546432
	1607400546432 [label=AccumulateGrad]
	1607400546864 -> 1607400546624
	1607290976720 [label="layer3.34.bn1.bias
 (256)" fillcolor=lightblue]
	1607290976720 -> 1607400546864
	1607400546864 [label=AccumulateGrad]
	1607400547104 -> 1607400547584
	1607290977280 [label="layer3.34.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607290977280 -> 1607400547104
	1607400547104 [label=AccumulateGrad]
	1607400547632 -> 1607400547824
	1607290977200 [label="layer3.34.bn2.weight
 (256)" fillcolor=lightblue]
	1607290977200 -> 1607400547632
	1607400547632 [label=AccumulateGrad]
	1607400548016 -> 1607400547824
	1607290977360 [label="layer3.34.bn2.bias
 (256)" fillcolor=lightblue]
	1607290977360 -> 1607400548016
	1607400548016 [label=AccumulateGrad]
	1607400548256 -> 1607400548736
	1607290977840 [label="layer3.34.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607290977840 -> 1607400548256
	1607400548256 [label=AccumulateGrad]
	1607400548928 -> 1607400549168
	1607290977920 [label="layer3.34.bn3.weight
 (1024)" fillcolor=lightblue]
	1607290977920 -> 1607400548928
	1607400548928 [label=AccumulateGrad]
	1607400549024 -> 1607400549168
	1607290978000 [label="layer3.34.bn3.bias
 (1024)" fillcolor=lightblue]
	1607290978000 -> 1607400549024
	1607400549024 [label=AccumulateGrad]
	1607400549360 -> 1607400549504
	1607400549648 -> 1607400550320
	1607400030448 [label="layer3.35.conv1.weight
 (256, 1024, 1, 1)" fillcolor=lightblue]
	1607400030448 -> 1607400549648
	1607400549648 [label=AccumulateGrad]
	1607400550464 -> 1607400550560
	1607400030528 [label="layer3.35.bn1.weight
 (256)" fillcolor=lightblue]
	1607400030528 -> 1607400550464
	1607400550464 [label=AccumulateGrad]
	1607400550944 -> 1607400550560
	1607400030608 [label="layer3.35.bn1.bias
 (256)" fillcolor=lightblue]
	1607400030608 -> 1607400550944
	1607400550944 [label=AccumulateGrad]
	1607400551232 -> 1607400551712
	1607400031168 [label="layer3.35.conv2.weight
 (256, 256, 3, 3)" fillcolor=lightblue]
	1607400031168 -> 1607400551232
	1607400551232 [label=AccumulateGrad]
	1607400551856 -> 1607400551904
	1607400031088 [label="layer3.35.bn2.weight
 (256)" fillcolor=lightblue]
	1607400031088 -> 1607400551856
	1607400551856 [label=AccumulateGrad]
	1607400552240 -> 1607400551904
	1607400031248 [label="layer3.35.bn2.bias
 (256)" fillcolor=lightblue]
	1607400031248 -> 1607400552240
	1607400552240 [label=AccumulateGrad]
	1607400552576 -> 1607400552960
	1607400031728 [label="layer3.35.conv3.weight
 (1024, 256, 1, 1)" fillcolor=lightblue]
	1607400031728 -> 1607400552576
	1607400552576 [label=AccumulateGrad]
	1607400543888 -> 1607400554304
	1607400031808 [label="layer3.35.bn3.weight
 (1024)" fillcolor=lightblue]
	1607400031808 -> 1607400543888
	1607400543888 [label=AccumulateGrad]
	1607400553584 -> 1607400554304
	1607400031888 [label="layer3.35.bn3.bias
 (1024)" fillcolor=lightblue]
	1607400031888 -> 1607400553584
	1607400553584 [label=AccumulateGrad]
	1607400553296 -> 1607400553440
	1607400554112 -> 1607249824640
	1607400032928 [label="layer4.0.conv1.weight
 (512, 1024, 1, 1)" fillcolor=lightblue]
	1607400032928 -> 1607400554112
	1607400554112 [label=AccumulateGrad]
	1607290759840 -> 1607285390496
	1607400033008 [label="layer4.0.bn1.weight
 (512)" fillcolor=lightblue]
	1607400033008 -> 1607290759840
	1607290759840 [label=AccumulateGrad]
	1607400552720 -> 1607285390496
	1607400033088 [label="layer4.0.bn1.bias
 (512)" fillcolor=lightblue]
	1607400033088 -> 1607400552720
	1607400552720 [label=AccumulateGrad]
	1607290759744 -> 1607290759360
	1607400033648 [label="layer4.0.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1607400033648 -> 1607290759744
	1607290759744 [label=AccumulateGrad]
	1607290759456 -> 1607290759984
	1607400033568 [label="layer4.0.bn2.weight
 (512)" fillcolor=lightblue]
	1607400033568 -> 1607290759456
	1607290759456 [label=AccumulateGrad]
	1607290760272 -> 1607290759984
	1607400033728 [label="layer4.0.bn2.bias
 (512)" fillcolor=lightblue]
	1607400033728 -> 1607290760272
	1607290760272 [label=AccumulateGrad]
	1607290760752 -> 1607290761232
	1607400034208 [label="layer4.0.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1607400034208 -> 1607290760752
	1607290760752 [label=AccumulateGrad]
	1607290761472 -> 1607290761808
	1607400034288 [label="layer4.0.bn3.weight
 (2048)" fillcolor=lightblue]
	1607400034288 -> 1607290761472
	1607290761472 [label=AccumulateGrad]
	1607290761568 -> 1607290761808
	1607400034368 [label="layer4.0.bn3.bias
 (2048)" fillcolor=lightblue]
	1607400034368 -> 1607290761568
	1607290761568 [label=AccumulateGrad]
	1607290761904 -> 1607290762144
	1607290761904 [label=CudnnBatchNormBackward0]
	1607290759264 -> 1607290761904
	1607290759264 [label=ConvolutionBackward0]
	1607400553968 -> 1607290759264
	1607285377344 -> 1607290759264
	1607400032208 [label="layer4.0.downsample.0.weight
 (2048, 1024, 1, 1)" fillcolor=lightblue]
	1607400032208 -> 1607285377344
	1607285377344 [label=AccumulateGrad]
	1607290760128 -> 1607290761904
	1607400032288 [label="layer4.0.downsample.1.weight
 (2048)" fillcolor=lightblue]
	1607400032288 -> 1607290760128
	1607290760128 [label=AccumulateGrad]
	1607290761088 -> 1607290761904
	1607400032368 [label="layer4.0.downsample.1.bias
 (2048)" fillcolor=lightblue]
	1607400032368 -> 1607290761088
	1607290761088 [label=AccumulateGrad]
	1607290762432 -> 1607290763296
	1607400034768 [label="layer4.1.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1607400034768 -> 1607290762432
	1607290762432 [label=AccumulateGrad]
	1607290763536 -> 1607290763776
	1607400034848 [label="layer4.1.bn1.weight
 (512)" fillcolor=lightblue]
	1607400034848 -> 1607290763536
	1607290763536 [label=AccumulateGrad]
	1607290764016 -> 1607290763776
	1607400034928 [label="layer4.1.bn1.bias
 (512)" fillcolor=lightblue]
	1607400034928 -> 1607290764016
	1607290764016 [label=AccumulateGrad]
	1607290764400 -> 1607290764784
	1607400035488 [label="layer4.1.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1607400035488 -> 1607290764400
	1607290764400 [label=AccumulateGrad]
	1607290764976 -> 1607290765216
	1607400035408 [label="layer4.1.bn2.weight
 (512)" fillcolor=lightblue]
	1607400035408 -> 1607290764976
	1607290764976 [label=AccumulateGrad]
	1607290759552 -> 1607290765216
	1607400035568 [label="layer4.1.bn2.bias
 (512)" fillcolor=lightblue]
	1607400035568 -> 1607290759552
	1607290759552 [label=AccumulateGrad]
	1607290758640 -> 1607290764880
	1607400035968 [label="layer4.1.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1607400035968 -> 1607290758640
	1607290758640 [label=AccumulateGrad]
	1607290762336 -> 1607290760416
	1607400036048 [label="layer4.1.bn3.weight
 (2048)" fillcolor=lightblue]
	1607400036048 -> 1607290762336
	1607290762336 [label=AccumulateGrad]
	1607290764064 -> 1607290760416
	1607400036128 [label="layer4.1.bn3.bias
 (2048)" fillcolor=lightblue]
	1607400036128 -> 1607290764064
	1607290764064 [label=AccumulateGrad]
	1607290760704 -> 1607290760656
	1607290760944 -> 1607290763440
	1607400036608 [label="layer4.2.conv1.weight
 (512, 2048, 1, 1)" fillcolor=lightblue]
	1607400036608 -> 1607290760944
	1607290760944 [label=AccumulateGrad]
	1607290763680 -> 1607290760224
	1607400036688 [label="layer4.2.bn1.weight
 (512)" fillcolor=lightblue]
	1607400036688 -> 1607290763680
	1607290763680 [label=AccumulateGrad]
	1607290760080 -> 1607290760224
	1607400036768 [label="layer4.2.bn1.bias
 (512)" fillcolor=lightblue]
	1607400036768 -> 1607290760080
	1607290760080 [label=AccumulateGrad]
	1607290760032 -> 1607290759024
	1607400037248 [label="layer4.2.conv2.weight
 (512, 512, 3, 3)" fillcolor=lightblue]
	1607400037248 -> 1607290760032
	1607290760032 [label=AccumulateGrad]
	1607290759648 -> 1607289721888
	1607400037168 [label="layer4.2.bn2.weight
 (512)" fillcolor=lightblue]
	1607400037168 -> 1607290759648
	1607290759648 [label=AccumulateGrad]
	1607290759120 -> 1607289721888
	1607400037328 [label="layer4.2.bn2.bias
 (512)" fillcolor=lightblue]
	1607400037328 -> 1607290759120
	1607290759120 [label=AccumulateGrad]
	1607289728512 -> 1607284119520
	1607400037808 [label="layer4.2.conv3.weight
 (2048, 512, 1, 1)" fillcolor=lightblue]
	1607400037808 -> 1607289728512
	1607289728512 [label=AccumulateGrad]
	1607289721984 -> 1607286568992
	1607400037888 [label="layer4.2.bn3.weight
 (2048)" fillcolor=lightblue]
	1607400037888 -> 1607289721984
	1607289721984 [label=AccumulateGrad]
	1607289725632 -> 1607286568992
	1607400037968 [label="layer4.2.bn3.bias
 (2048)" fillcolor=lightblue]
	1607400037968 -> 1607289725632
	1607289725632 [label=AccumulateGrad]
	1607287480352 -> 1607289354512
	1607275715440 -> 1607275723360
	1607275715440 [label=TBackward0]
	1607287812016 -> 1607275715440
	1607274693488 [label="fc.weight
 (1000, 2048)" fillcolor=lightblue]
	1607274693488 -> 1607287812016
	1607287812016 [label=AccumulateGrad]
	1607275723360 -> 1607400565056
}
